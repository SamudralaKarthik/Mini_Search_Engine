next prev kafka tutori python follow tutori will discuss apach kafka along with python program languag understand apach kafka apach kafka open sourc stream platform that origin design linkedin later hand over apach foundat open sourc definit from wikipedia apach kafka open sourc platform develop apach softwar foundat use process stream written java scala goal project offer high throughput unifi low latenc platform order handl real time data feed storag layer apach kafka fundament massiv scalabl pub sub messag queue design distribut transact log that make extrem valuabl enterpris infrastructur order process stream data moreov kafka connect extern system for import export data through kafka connect offer kafka stream librari java stream process think giant commit where store data order happen user thi just access util their need some case apach kafka apach kafka differ place consid some case kafka that could help figur usag activ monitor kafka monitor activ activ could belong physic sensor devic websit produc publish data from data sourc that later util find trend pattern messag also kafka messag broker among servic implement microservic architectur have microservic produc anoth consum exampl have microservic respons creat account send email user relat account creation aggreg also util kafka collect log from distinct system store them central system further process etl kafka offer featur almost real time stream henc develop base requir databas base thing have mention earlier that kafka also act databas typic databas that featur data queri requir kafka store data long requir without consum understand concept kafka discuss core concept kafka topic everi messag that feed into system must part some topic topic stream record messag store format key valu pair everi messag assign sequenc known offset result messag could input other further process produc produc applic respons publish data into kafka system they publish data topic their choic consum there consum applic that use messag publish into topic consum get subscript topic prefer consum data broker broker instanc kafka which respons messag exchang kafka part cluster stand alon machin now consid simpl exampl there down warehous restaur where materi store such veget rice flour more restaur serv variou kind dish like indian italian chines mani more cook each cuisin refer warehous select requir object make dish there chanc that cook from differ cuisin same stuff made materi thi secret ingredi that util everi kind dish follow case warehous act broker merchant good produc good secret ingredi creat cook topic cook consum access kafka python there variou librari avail python program languag kafka some these librari describ below librari descript kafka python thi open sourc librari design python commun pykafka thi librari maintain parsli claim python api howev can not creat dynam topic thi librari like kafka python confluent python kafka thi librari provid confluent thin wrapper around librdkafka thu perform better than abov two instal depend will kafka python thi project instal manual use instal shown below syntax instal kafka python now start build project project code follow exampl will creat produc that produc number rang from send them kafka broker later consum will read that data from broker keep them mongodb collect benefit util kafka that case consum break down anoth fix consum will continu read where earlier left thi good method confirm that data into databas without miss data duplic follow exampl creat python program file name produc begin with import some requir librari modul file produc import requir librari from time import sleep from json import dump from kafka import kafkaproduc explan abov snippet code have import requir librari modul now initi kafka produc note follow paramet bootstrap server localhost thi paramet set host port contact produc bootstrap initi cluster metadata mandatori thi here default host port localhost valu serial lambda dump encod utf thi paramet function serial data befor send broker here transform data into json file encod utf consid follow snippet code same file produc initi kafka produc produc kafkaproduc bootstrap server localhost valu serial lambda dump encod utf explan abov snippet code have initi kafka produc use kafkaproduc function where have use paramet describ abov now have gener number rang from perform thi use for loop where everi number valu dictionari with key num thi use data onli topic within same loop will also send data broker perform thi call send method produc detail topic data note valu serial will automat transform encod data take five second break order conclud iter case have confirm whether broker receiv messag advis includ callback file produc gener number rang from rang data num produc send testnum valu data sleep explan abov snippet code have use for loop iter number rang from have also interv five second between each iter somebodi want test code recommend creat topic send data that newli gener topic thi method will avoid case duplic valu possibl confus testnum topic when will test produc consum togeth consum data befor start with code part consum creat python program file name consum will import some modul such json load mongocli kafkaconsum sinc pymongo scope thi tutori won dig deeper into code moreov somebodi also replac mongo code with other code need code thi order enter data into anoth databas code process data anyth els think consid follow snippet code begin with file consum import requir modul from json import load from kafka import kafkaconsum from pymongo import mongocli explan abov snippet code have import requir modul from their respect librari creat kafka consum will kafkaconsum function thi work let have closer look paramet use thi function topic first paramet kafkaconsum function topic follow case testnum bootstrap server localhost thi paramet same produc auto offset reset earliest thi paramet among other signific paramet handl where consum restart read after turn break down either latest earliest whenev earliest consum begin read latest commit offset whenev latest consum begin read log end that exactli what need here enabl auto commit true thi paramet confirm whether consum commit read offset each interv auto commit interv thi paramet use interv between commit messag come everi interv five second commit everi second appear fair group counter thi paramet group consum which consum belong note that consum must part consum group order make them work automat commit valu deseri use deseri data into gener json format invers work valu serial consid follow snippet code same file consum gener kafka consum consum kafkaconsum testnum bootstrap server localhost auto offset reset earliest enabl auto commit true group group valu deseri lambda load decod utf explan abov snippet code have use kafkaconsum function gener kafka consum have also paramet within function that studi earlier now consid follow snippet code connect testnum collect thi collect similar tabl relat databas mongodb databas file consum client mongocli localhost collect client testnum testnum explan abov snippet code have defin variabl client that use mongocli function specifi with host port have then defin anoth variabl collect that use client variabl access data testnum topic thi data extract from consum loop through here consum consid iter consum will keep listen until broker doe respond anymor access messag valu use valu attribut here overwrit messag with messag valu next line insert data into databas collect last line will print confirm that messag collect note possibl insert callback action thi loop file consum messag consum messag messag valu collect insert one messag print messag collect explan abov snippet code have use for loop iter through consum order extract data order test code execut produc file first then consum next topicaug assign express python prev next