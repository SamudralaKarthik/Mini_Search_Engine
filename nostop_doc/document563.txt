next prev Python urllib Library Python's urllib.request HTTP Requests this tutorial, will learn about Python urllib.request make request sample URL. will also make request sample REST some JSON data. will also learn about POST request using urllib.request library. urllib library plays essential role opening using Python code. This library many features besides opening URLs. Later explore important features. Let's have brief introduction urllib library. Python urllib Module Python urllib module allows access website Python code. This facility urllib provides flexibility GET, POST, methods mock JSON data Python code. download data, access websites, parse data, modify headers using urllib library. There versions urllib urllib2 urllib3. urllib2 used Python urllib used Python urllib3 some advanced features. websites don't allow programs invade their website's data load their servers. When they find such programs, they sometimes choose block program serve different data that regular user might use. However, overcome such situations with simple code. only need modify user-agent, which included request header that send those don't know, headers bits data that share server that server know about where Python version informs websites that trying access website with urllib Python versions. urllib module consists several modules working with URLs. These given below urllib.request opening reading. urllib.parse parsing URLs urllib.error exceptions raised urllib.robotparser parsing robot.txt files Most time, urllib package comes with Python installation your environment. download using below command. install urllib will install urllib your environment. Basic HTTP Messages understand urllib.request better way, need know about HTTP message. HTTP message known text, transmitted stream bytes that follow guideline specified 7230. decoded HTTP message simple below. HTTP/1.1 Host: www.google.com request specifies root using HTTP/1.1 protocol. HTTP method main parts -metadata body. above message metadata nobody. response also consists parts HTTP/1.1 Content-Type: text/html; charset=ISO-8859-1 Server: gws (... other headers ...) <!doctype html><html itemscope="" itemtype="http://schema.org/WebPage" see, response starts with status code metadata response. have shown standard HTTP message, some break these rules follows older specification. many key-value pair data, such representing response headers. urllib.request Let's understand following example urllib.request.OpenURL() method. need import urllib3 module assign opening variable, where read() command read data. When request with urllib.request.urlopen(), returns HTTPResponse object. print HTTPResponse object using dir() function different methods properties. Example from urllib.request import urlopen with urlopen("https://www.google.com") response: print(dir(response)) Output: ['__abstractmethods__', '__class__', '__del__', '__delattr__', '__dict__', '__dir__', '__doc__', '__enter__', '__eq__', '__exit__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__next__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '_abc_impl', '_checkClosed', '_checkReadable', '_checkSeekable', '_checkWritable', '_check_close', '_close_conn', '_get_chunk_left', '_method', '_peek_chunked', '_read1_chunked', '_read_and_discard_trailer', '_read_next_chunk_size', '_read_status', '_readall_chunked', '_readinto_chunked', '_safe_read', '_safe_readinto', 'begin', 'chunk_left', 'chunked', 'close', 'closed', 'code', 'debuglevel', 'detach', 'fileno', 'flush', 'fp', 'getcode', 'getheader', 'getheaders', 'geturl', 'headers', 'info', 'isatty', 'isclosed', 'length', 'msg', 'peek', 'read', 'read1', 'readable', 'readinto', 'readinto1', 'readline', 'readlines', 'reason', 'seek', 'seekable', 'status', 'tell', 'truncate', 'url', 'version', 'will_close', 'writable', 'write', 'writelines'] Example import urllib.request request_url urllib.request.urlopen('https://www.google.com/') print(request_url.read()) Output: b'<!doctype html><html itemscope="" itemtype="http://schema.org/WebPage" lang="en-IN"><head><meta content="text/html; charset=UTF-8" http-equiv="Content-Type"><meta content="/images/branding/googleg/1x/googleg_standard_color_128dp.png" itemprop="image"><title>Google</title><script nonce="miKBzQYvtiMON4gUmZ+2qA==">(function(){window.google={kEI:\'lj1QYuXdLNOU-AaAz5XIDg\',kEXPI:\'0,1302536,56873,1710,4348,207,4804,2316,383,246,5,1354,4013,1238,1122515,1197791,610,380090,16114,19398,9286,17572,4859,1361,9290,3027,17582,4020,978,13228,3847,4192,6430,22112,629,5081,1593,1279,2742,149,1103,841,6296,3514,606,2023,1777,520,14670,3227,2845,7,17450,16320,1851,2614,13142,3,346,230,1014,1,5444,149,11325,2650,4,1528,2304,6463,576,22023,3050,2658,7357,30,13628,13795,7428,5800,2557,4094,4052,3,3541,1,16807,22235,2,3110,2,14022,1931,784,255,4550,743,5853,10463,1160,4192,1487,1020,2381,2718,18233,28,2,2,5,7754,4567,6259,3008,3,3712,2775,13920,830,422,5835,11862,3105,1539,2794,8,4669,1413,1394,445,2,2,1,6395,4561,10491,2378,701,252,1407,10,1,8591,113,5011,5,1453,637,162,2,460,2,430,586,969,593,5214,2215,2343,1866,1563,4987,791,6071,2,1,5829,227,161,983,3110,773,1217,2780,933,504,1259,957,749,6,601,23,31,748,100,1392,2738,92,2552,106,197,163,1315,1133,316,364,810,3,333,233,1586,229,81,967,2,440,357,298,258,1863,400,1698,417,4,881,219,20,396,2,397,481,75,5444944,1269,5994875,651,2801216,882,444,3,1877,1,2562,1,748,141,795,563,1,4265,1,1,2,1331,4142,2609,155,17,13,72,139,4,2,20,2,169,13,19,46,5,39,96,548,29,2,2,1,2,1,2,2,7,4,1,2,2,2,2,2,2,353,513,186,1,1,158,3,2,2,2,2,2,4,2,3,3,269,1601,141,1002,98,214,133,10,9,9,2,10,3,1,11,10,6,239 above code returns source code www.google.com; clean results using regular expression. webpages made using HTML, CSS, JavaScript, program only extracts text usually. Hence regular expression becomes useful; will next section. There methods data transfer POST. method used fetch data, POST method used send data over server, same post some data request based post. also make request using POST from/to URL. let's uses urllib.parse. urllib.parse urllib.parse helps define function manipulate URLs their components parts create destroy them. There hard code value pass URL, urllib Let's understand following example. Example used parse values into import urllib.parse 'https://www.google.com/search' values {'query' 'python tutorial'} above code, defined values with POST method send with URL. first need encode values. encode utf-8 bytes. encoded dictionary request. Then, open using with request. Finally, read that response with read(). Example data urllib.parse.urlencode(values) data data.encode('utf-8') data should bytes urllib.request.Request(url, data) resp urllib.request.urlopen(req) respData resp.read() print(respData) Output: urllib.error.HTTPError: HTTP Error 405: Method Allowed When above code, Google will return 405, method allowed. Google doesn't allow sending request using Python script. another website with search send request using Python. Sometimes websites don't like visited spammers robots, they might treat them differently. past time, most website blocks program. Wikipedia used outright block programs, they serve page like Google. send header each time request URL, which basic information about There user-agent value within header that defines browser accessing website's server. that's Google analytics determines what browser using. default, user-agent with urllib using Python version. either unknown websites; otherwise, they will block entirely. Example import urllib.parse import urllib.request try: 'https://www.google.com/search?q=python-tutorial' now, with below headers, defined ourselves simpleton still using internet explorer. headers headers['User-Agent'] "Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.17 (KHTML, like Gecko) Chrome/24.0.1312.27 Safari/537.17" request urllib.request.Request(url, headers headers) resp urllib.request.urlopen(request) respData resp.read() saveFile open('ModifyHeaders.txt','w') saveFile.write(str(respData)) saveFile.close() except Exception print(str(e)) have modified headers same thing. make request, response indeed different. Common urllib.request Troubles program throw error while running urllib.request program. this section, will deal with couple most common errors when getting started. Before understanding specific errors, will learn implement error handling. Implement Error Handling development plagued with errors, take lots time resolve. will define handle HTTP, URL, timeout errors when using urllib.request. HTTP status code attached with every response status line. read status code response, request reaches target. There predefined status codes that used with response. example represent successful requests. request code 405, means there something wrong. There also connection error, provided isn't correct. this case, urllib.request will raise error. Finally, server takes lots time respond. Maybe network connection slow, server down, server programmed ignore specific requests. overcome this, pass timeout argument urlopen() function raise TimeoutError after certain time. need catch them first using tryâ€¦.expect clause solve these problems. Example from urllib.error import HTTPError, URLError from urllib.request import urlopen request_func(url): try: with urlopen(url, timeout=10) response: print(response.status) return response.read(), response except HTTPError error: print(error.status, error.reason) except URLError error: print(error.reason) except TimeoutError: print("Request timed out") request_func() function takes string argument, which will fetch request from with urllib.request. correct, will catch URLError. also catches HTTPError's object that's raised error. there error, will print status return body response. observe, have called urlopen() function with timeout parameter, which will reason TimeoutError raised after seconds specified. program will wait seconds, which good amount time wait response. Handling Error status means that server understood request won't fulfill common error when work with web-scraping. discussed above, this error solved using User-Agent header. mainly related 4xx codes sometimes confused. Unauthorized Forbidden Error returned server user isn't identified logged must something gain access, like register. Error returned server user identified doesn't have access resource. Luckily handle such error modifying User-Agent string web, including user agent database. Request Package Ecosystem This section will clarify package ecosystem around HTTP requests with Python. There multiple packages with clear standard. must familiar with correct package requirements. What urllib2 urllib3? urllib library split into parts. look back early version Python when original urllib introduced, around version 1.6, revamped urllib2 added. when Python introduced, original urllib deprecated, urllib2 dropped taking original urllib name. urllib.error urllib.parse urllib.request urllib.response urllib.robotparser urllib3 third-party library developed while urllib2 still around. independently maintained library. When Should requests over urllib.requests important know when request urllib.request library. urllib.request meant low-level library that reveals many details about working HTTP requests. request library highly recommended when users interact with many different REST APIs. official documentation request library claims that "built human beings" successfully created intuitive, secure, straightforward around HTTP. request library allows complex tasks easily, especially when comes character encoding. With urllib library, have aware encoding take steps ensure error-free experience. more focused learning about more standard Python deal with HTTP request, urllib.request best start. could even further very low-level http modules. Conclusion have discussed urllib library detail learned make request using Python script. this built-in module project, keeping them dependency-free longer. This tutorial explored urllib library lower-level module, such urllib.request also explained deal with common error resolve them. Next TopicFiona module Python prev next