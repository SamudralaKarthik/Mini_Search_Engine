next prev Cache Python this tutorial, will learn about cache Python. will learn caching strategies implement them using Python decorators, strategy, works. will also discuss improve performance caching with @lru_cache decorator. This tutorial consists deeper understanding caching works benefit from Python. First, let's understand what caching uses. Caching Uses Caching best technique memory management, which restores most recent often data memory that access faster computationally cheaper than their actual source. cache follows First First format. Let's take real life example understand better way. Suppose creating website that fetches articles from different sites. user clicks particular list, application downloads articles shows screen. What happen when users decide move back visited articles? application facilitates with caching technique then will download same content again again. That would make application's system very slow extra pressure server hosting articles. application would store content locally after fetching each article overcome such situation. next time user decided open article, application would fetch content from locally stored copy instead going back resource. This technique known caching. What Caching? Caching known Least Recently Used, which common caching strategy define policy evict elements make place elements. discards least recently used items first when cache full. LRU, there references used Page reference page found main memory, page hit. Page Fault just opposite page hit. page fault occurs reference page found memory. Implementing Cache Using Python Dictionary implement caching solution using Python dictionary. Let's take articles reference; instead visiting direct server, check cache return server. Let's understand following example. Example import requests cache dict() download_article_from_server(url): print("Fetching article from server...") response requests.get(url) return response.text get_article(url): print("Getting article...") cache: cache[url] download_article_from_server(url) return cache[url] get_article("https://www.javatpoint.com/python-applications/") get_article("https://www.javatpoint.com/how-to-install-python/") Output: Getting article... Fetching article from server... Getting article... Fetching article from server... Explanation above code, that string "Fetching article from server" because after accessing article first time, content cache dictionary. When code second time, don't need fetch item from server again. Various Caching Strategies need have proper strategy decide make application more efficient. application, when user downloads more articles, keeps storing them memory, which lead application crash. suitable strategy resolve such issue using algorithms that focus managing cache information which item remove make room item. There various strategies that used expel cache make space one. Let's popular caching strategies below. Strategy Eviction Policy case First-In/First-Out (FIFO) evicts oldest entries. Newer entries most likely reused. Last-In/First-Out (LIFO) evicts latest entries. Older entries most likely reused Least Recently Used (LRU) evicts least recently used entry evicts least recently used entry Most Recently Used (MRU) Evicts most recently used entry. least recently used entries most likely reused. Least Frequently Used (LFU) Evicts least often accessed entry Entries with hits more likely reused will Python's @lru_cache decorator functools module upcoming section. (Least Recent Used) Caching Strategy strategy popularly known organizing items use. algorithm moves entry cache when access this algorithm identifies entry that's gone unused checking bottom list. When entry comes, pushes first entry down list. This algorithm assumes that more likely will needed future object been used. Create Cache Python this section, will create simple cache implementation using Python's features. Python comes with hash table known OrderedDict that keeps order insertion keys. following strategy achieve create get() function that removes dictionary adds ordered keys. create put() function that checks space; space filled, first entry ordered keys replaced with latest entry. works because every get() moves item ordered keys; hence, first item least recently used. Example from collections import OrderedDict class LRUCacheImplement: __init__(self, size): self.size size self.lru_cache OrderedDict() get(self, key): try: value self.lru_cache.pop(key) self.lru_cache[key] value return value except KeyError: return put(self, key, value): try: self.lru_cache.pop(key) except KeyError: len(self.lru_cache) self.size: self.lru_cache.popitem(last=False) self.lru_cache[key] value show_entries(self): print(self.lru_cache) Create Cache with size cache LRUCacheImplement(3) cache.put("1","1") cache.put("2","2") cache.put("3","3") cache.get("1") cache.get("3") cache.put("4","4") cache.show_entries() cache.put("5","5") cache.show_entries() Output: OrderedDict([('1', '1'), ('3', '3'), ('4', '4')]) OrderedDict([('3', '3'), ('4', '4'), ('5', '5')]) Explanation Let's breakdown code created cache that hold three items. cache.put('1', '1') function stored last OrderedDict same cache.put('2', '2') cache.put('3', '3'). elements stored When cache.get('1') called, removed from front added last. elements stored When cache.get('1') called, removed from front added last. elements stored When called cache.put('4', '4'), removed from front added back, elements stored When called cache.put('5', '5'), removed from front added back, finally, elements stored 5]. Create Cache Python Using functools Here will @lru_cache decorator functools module. However, @lru_cache uses behind scene. apply this decorator function which takes potential input returns corresponding data object. advantage that when function called again, decorator will execute function statements data corresponding already present cache. Let's understand following example. Example from functools import lru_cache @lru_cache(maxsize=4) get_value(key): print("Cache miss with "+key) return ":value" print(get_value("1")) print(get_value("2")) print(get_value("3")) print(get_value("4")) print(get_value("4")) print(get_value("3")) print(get_value("1")) print(get_value("7")) print(get_value("6")) print(get_value("3")) print(get_value("1")) Output: Cache miss with value Cache miss with value Cache miss with value Cache miss with value value value value Cache miss with value Cache miss with value value value Evicting Cache Entries Based Both Time Space @lru_cache decorator expels existing entries only when there space stores more entries. entries sufficient, they will live last long never refresh. implement such functionality update cache system, expires after specific time. implement using @lru_cache, discussed earlier. caller tries access item past lifetime, cache won't return content force caller fetch result directly from network. Let's understand following example Example from functools import lru_cache, wraps from datetime import datetime, timedelta timed_lru_cache(seconds: int, maxsize: 128): wrapper_cache(func): func lru_cache(maxsize=maxsize)(func) func.lifetime timedelta(seconds=seconds) func.expiration datetime.utcnow() func.lifetime @wraps(func) wrapped_func(*args, **kwargs): datetime.utcnow() func.expiration: func.cache_clear() func.expiration datetime.utcnow() func.lifetime return func(*args, **kwargs) return wrapped_func return wrapper_cache Let's breakdown code @timed_lru_decorator used support lifetime entries cache maximum size cache. wrap_cache function, lru_cache implement same functionalities remaining lines instrument decorator function with attributes representing lifetime cache actual data when expire. wrapped_func function, decorator checks whether current past expiration date. happens, removes entries from cache recomputes lifetime expiration date. implement this strategy more sophisticatedly evicting entries based their individual lifetimes. Conclusion Caching important strategy improving performance software system. have explained some important concepts related implement using various techniques such @lru_cache OrderDict. also includes measure runtime code using timeit module. Next TopicPython List Comprehension Generator Expression prev next