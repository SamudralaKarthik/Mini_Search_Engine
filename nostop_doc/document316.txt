next prev Missing Data Conundrum: Exploration Imputation Techniques Missing data most common non-negotiable problem statistical analysis machine learning. They affect data quality. happen various reasons such user responding questions recommender system, death patient treatment non-compliance, this tutorial, will discuss importance missing data identify reason missing data. Missing Data Mechanism current era, Data treated fuel means data most powerful thing. used many ways. incomplete data lead problem. first, need understand importance data, more importantly, need identify reason missing data occurrence comprehensively. data collection process also plays important role identify data collection errors. mechanism missing data categorized into three major classes. These categories based nature missing data observed data. These mechanisms given below. Missing Completely Random (MCAR) nature missing data related observed data missing data. example Children missing their classes because their parents moving different city hence, children leave study. Missing Random (MAR) nature missing data related observed data missing data. example Children missing their classes because their parents moving different city hence, children leave study. Missing Random (MNAR) also known non-ignorable because missingness mechanism cannot ignored. happen only when there neither MCAR MAR. missing value variable related that both observed unobserved variables. example Parent refuses send their children study center toxic atmosphere they want their children bullied. problem with MNAR data intrinsically associated with issue identifiability. Understanding data collection process substantive scientific knowledge helps assume data mechanism. Statistical testing also helps understand type missing data mechanism. There many modules that handle missing data effectively, fancyimpute module quite useful popular. Fancyimpute Module Missing data plays important role creating predictive model; algorithms perform very well with missing dataset. Fancyimpute machine learning library missing data imputation algorithm. uses machine-learning algorithm impute missing values. Fancyimpute uses entire column impute missing values. provides ways impute missing data K-Nearest Neighbor MICE Multiple Imputation Chained Equation K-Nearest Neighbor finds similar data points among features fill missing value. Let's understand following example. Example import pandas import numpy importing from fancyimpute library from fancyimpute import pd.DataFrame([[np.nan, np.nan, np.nan, [np.nan, np.nan, np.nan, [np.nan, np.nan, 9]], columns list('ABCD')) printing dataframe print(df) calling class knn_imputer KNN() imputing missing value with knn imputer knn_imputer.fit_transform(df) printing dataframe print(df) Output: Imputing with missing, elapsed time: 0.001 [[4.80735271 7.70802941 7.57627146 [5.29411783 7.49760549 7.64000033 [6.2499999 7.87179494 [9. Multiple Imputations Chained Equation this method, mice multiple imputations instead single imputation. performs multiple regressions over sample data takes averages them. Let's understand following example. Example import pandas import numpy importing MICE from fancyimpute library from fancyimpute import IterativeImputer pd.DataFrame([[np.nan, np.nan], [23, np.nan, [np.nan, np.nan, np.nan, [np.nan, np.nan, [15, 29], [20, 91]], columns list('ABCD')) printing dataframe print(df) calling MICE class mice_imputer IterativeImputer() imputing missing value with mice imputer mice_imputer.fit_transform(df) printing dataframe print(df) Output: 15.0 23.0 40.0 15.0 70.0 28.0 29.0 20.0 35.0 57.0 91.0 32.13508529 -76.25883183] 23.80426163 24.47759791 32.58430591 26.67745156 31.14858991 32.06817994 57. 91. Handling Missing Data There many methods available treat missing data literature, textbook standard courses. have discussed important methods fancyimputer. However, these methods consist some drawbacks. When using data mining process, need careful avoid bias overestimate variability; these methods don't perform well. Case Deletion There types case deletion methods. first list deletion (also known complete case analysis) second method pair deletion. case deletion methods used delete missing cases from dataset analysis-by-analysis basis. Let's create dummy dataset which contains some missing values using pandas dataframe. Example import pandas import numpy import fancyimpute from sklearn.impute import SimpleImputer data {'Name': ['John','Paul', np.NaN, 'Wale', 'Mary', 'Carli', 'Steve'], 'Age': [21,23,np.nan,19,25,np.nan,15],'Sex': ['M',np.nan,np.nan,'M','F','F','M'],'Goals': [5,10,np.nan,19,5,0,7],'Assists': [7,4,np.nan,9,7,6,4],'Value': [55,84,np.nan,90,63,15,46]} df=pd.DataFrame(data, columns =['Name','Age','Sex','Goals', 'Assists', 'Value']) print(df) Output: Name Goals Assists Value John 21.0 55.0 Paul 23.0 10.0 84.0 Wale 19.0 19.0 90.0 Mary 25.0 63.0 Carli 15.0 Steve 15.0 46.0 above code, have created dataset that contains missing values. remove missing values using df.dropna() method that removes missing value. Let's below output. Example import pandas import numpy import fancyimpute from sklearn.impute import SimpleImputer data {'Name': ['John','Paul', np.NaN, 'Wale', 'Mary', 'Carli', 'Steve'], 'Age': [21,23,np.nan,19,25,np.nan,15],'Sex': ['M',np.nan,np.nan,'M','F','F','M'],'Goals': [5,10,np.nan,19,5,0,7],'Assists': [7,4,np.nan,9,7,6,4],'Value': [55,84,np.nan,90,63,15,46]} df=pd.DataFrame(data, columns =['Name','Age','Sex','Goals', 'Assists', 'Value']) print(df.dropna()) Output: Name Goals Assists Value John 21.0 55.0 Wale 19.0 19.0 90.0 Mary 25.0 63.0 Steve 15.0 46.0 also df.dropna(how 'all') which removes just rows with missing values. also specify removing column with missing values using df.dropna(axis 'all'). Let's understand below example. Example import pandas import numpy import fancyimpute from sklearn.impute import SimpleImputer data {'Name': ['John','Paul', np.NaN, 'Wale', 'Mary', 'Carli', 'Steve'], 'Age': [21,23,np.nan,19,25,np.nan,15],'Sex': ['M',np.nan,np.nan,'M','F','F','M'],'Goals': [5,10,np.nan,19,5,0,7],'Assists': [7,4,np.nan,9,7,6,4],'Value': [55,84,np.nan,90,63,15,46]} df=pd.DataFrame(data, columns =['Name','Age','Sex','Goals', 'Assists', 'Value']) print(df.dropna(how 'all')) Output: Name Goals Assists Value John 21.0 55.0 Paul 23.0 10.0 84.0 Wale 19.0 19.0 90.0 Mary 25.0 63.0 Carli 15.0 Steve 15.0 46.0 Example import pandas import numpy import fancyimpute from sklearn.impute import SimpleImputer data {'Name': ['John','Paul', np.NaN, 'Wale', 'Mary', 'Carli', 'Steve'], 'Age': [21,23,np.nan,19,25,np.nan,15],'Sex': ['M',np.nan,np.nan,'M','F','F','M'],'Goals': [5,10,np.nan,19,5,0,7],'Assists': [7,4,np.nan,9,7,6,4],'Value': [55,84,np.nan,90,63,15,46]} df=pd.DataFrame(data, columns =['Name','Age','Sex','Goals', 'Assists', 'Value']) print(df.dropna(axis=1, how='all')) Output: Name Goals Assists Value John 21.0 55.0 Paul 23.0 10.0 84.0 Wale 19.0 19.0 90.0 Mary 25.0 63.0 Carli 15.0 Steve 15.0 46.0 Conclusion this tutorial, have discussed importance missing data data science projects. reviews exploration techniques important imputation methods used handling missing data. have also described method handling missing value. wildly used model assumes joint distribution missing values estimates model parameters describing observed data. Next TopicDifferent Methods Array Rotation Python prev next