next prev Effective Root Searching Algorithms Python Data Scientists Computer Scientists, often deal with root searching algorithms daily routines even realize These algorithms designed locate proximity specific value, local/global maxima, minima. utilize root searching algorithm order search proximity specific value, local/global maxima, minima. mathematics, finding root generally means that attempting solve system equation(s) like f(X) This will make root searching algorithms very efficient searching algorithm well. have perform define g(X) f(X) where search target instead solve like g(X) f(X) Approaches mainly categorized into different families: Bracket Approaches (For example, Bisection Algorithm) Iterative Approaches (For example, Newton's Method, Secant Method, Steffensen's Method, more) following tutorial, will understanding implementation some these algorithms Python programming language comparing them against each other. These algorithms follows: Bisection Algorithm Regula-Falsi Algorithm Illinois Algorithm Secant Algorithm Steffensen's Algorithm Before started, assume that have continuous function would like search value Thus, solving equation: f(x) Understanding Bisection Algorithm Bisection Algorithm, also known discrete version (Binary search) tree variant (Binary search tree), effective algorithm search target value within boundary. that, this algorithm also called bracketing approach finding root algorithm. Strength: Bisection Algorithm robust algorithm that guarantees reasonable convergence rate target value. Weakness: This algorithm requires knowledge estimated area root. example, This algorithm works well; only root estimated area. Suppose that know that between f(p) f(q), which forms search bracket. algorithm will check whether greater than less than f((p which mid-point bracket. When searching continuous function, probably, will never able locate exact value (For example, locating ?). margin error needed check against mid-point bracket. treat error margin early stopping when computed value close target value. example, error margin 0.001%, 3.141624 close enough ?, approximately 3.1415926... calculated value close enough target value, search done, else, search value bottom half less than f((p vice versa. consider following snippet code demonstrating same Python. Example: bisectionAlgorithm(f, margin .00_001): Bracketed approach Root-finding with bisection method Arguments ---------- callable, continuous function float, lower bound searched float, upper bound searched float, target value margin: float, error margin absolute term Return Values ---------- float where f(r) within margin (lower f(p)) (upper f(q)): lower, upper upper, lower assert lower, smaller than lower bound. {lower}" assert upper, larger than upper bound. {upper}" while (p abs((y_r f(r)) margin: found! return elif y_r: upper else: lower Explanation: above snippet code, have defined function bisectionAlgorithm that accepts some parameters like margin where callable, continuous function, float value lower bound searched, also float value upper bound searched, again float value target value margin margin error absolute term also float value. have then used conditional statement check lower bound assigned f(p) greater than upper bound assigned f(q), which value equal lower upper equal upper lower. have then used assert keyword debug value have then used while loop within which have defined value equals mean Inside this loop, have also used if-elif-else conditional statement check assigned f(r) less than margin returned same. Understanding False Position Algorithm Similar Bisection algorithm, False Position Algorithm, also known Regula Falsi, utilizes bracketing approach. unlike Bisection Algorithm, does utilize brute-force approach dividing problem space into half every iteration. Instead, this algorithm iteratively draws straight line from f(p) f(q) compares intercept with target value. However, there guarantee that searching efficiency always improved. instance, following diagram depicts only lower bound been increased reducing rate, whereas upper bound remains stagnant bound. Figure Stagnant bound slows down convergence Strength: This algorithm often shows faster convergence than Bisection algorithm. Regula Falsi benefits that bracket gets smaller, continuous function will converge straight line. Weakness: Regula Falsi also shows slower convergence when algorithm hits stagnant bound. This algorithm requires knowledge approximate area root. example, significant difference implementation between Regula Falsi Bisection Algorithm that longer mid-point between q; however, instead being estimated consider following snippet code demonstrating same: Example: regulaFalsiAlgorithm(f, margin .00_001): Bracketed approach Root-finding with regula-falsi method Arguments ---------- callable, continuous function float, lower bound searched float, upper bound searched float, target value margin: float, error margin absolute term Return Values ---------- float where f(r) within margin assert (lower f(p)), smaller than lower bound. {lower}" assert (upper f(q)), larger than upper bound. {upper}" while (upper (lower y))) (upper lower) abs((y_r f(r)) margin: found! return elif y_r: upper else: lower Explanation: above snippet code, have defined function regulaFalsiAlgorithm that accepts some parameters like margin where callable, continuous function, float value lower bound searched, also float value upper bound searched, again float value target value margin margin error absolute term also float value. have then used assert keyword debug value have then used while loop within which have defined value Inside this loop, have also used if-elif-else conditional statement check assigned f(r) less than margin returned same. Understanding Illinois Algorithm (Modified Regula Falsi) order past stagnant bound, insert conditional rule when bound remain stagnant rounds. Taking previous example, moved rounds, that close root yet, next round, line will drawn f(q) instead f(q). same will implemented lower bound lower bound stagnant bound. Figure Illinois Algorithm avoid prolonged stagnant bound faster convergence. Strength: Illinois Algorithm shows faster convergence than both Bisection algorithm Regula Falsi algorithm. avoid stagnant bound halving distance stagnant bound target value. Weakness: This algorithm also shows slower convergence when algorithm hits stagnant bound. This algorithm requires knowledge estimated area root. example, Example: illinoisAlgorithm(f, margin .00_001): Bracketed approach Root-finding with illinois method Arguments ---------- callable, continuous function float, lower bound searched float, upper bound searched float, target value margin: float, error margin absolute term Return Values ---------- float where f(r) within margin assert (lower f(p)), smaller than lower bound. {lower}" assert (upper f(q)), larger than upper bound. {upper}" stagnant while (upper (lower y))) (upper lower) abs((y_r f(r)) margin: found! return elif y_r: upper stagnant Lower bound stagnant! lower lower) stagnant else: lower stagnant Upper bound stagnant! upper (upper stagnant Explanation: above snippet code, have defined function illinoisAlgorithm that accepts some parameters like margin where callable, continuous function, float value lower bound searched, also float value upper bound searched, again float value target value margin margin error absolute term also float value. have then used assert keyword debug value have then defined variable stagnant equals zero. have then used while loop within which have defined value Inside this loop, have also used if-elif-else conditional statement check assigned f(r) less than margin returned same. Understanding Secant Method (Quasi-Newton's Method) Till now, have been implementing bracket approaches. What don't know location brackets? such cases, secant method helpful. Secant method iterative algorithm that begins with values tries converge towards target value. While better performance while algorithm convergence don't require knowledge rough root location, into risk divergence initial values away from real root. Strength: Secant method does need bracket consisting root. This method does need knowledge estimated area root. Weakness: Unlike earlier methods, Secant method does guarantee convergence. Secant method begins checking user-defined seeds. Suppose want find root math.pi starting with x_0 seeds will respectively. (Note: This process similar searching like math.pi) Figure Secant's method locating based then locate intercept with target value drawing straight line through f(x_0) f(x_1) what have done Regula Falsi algorithm. f(x_2) close enough target value, must repeat step locate x_3. general, calculate next using following formula: consider following snippet code demonstrating same: Example: secantAlgorithm(f, iterations, margin .00_001): Iterative approach Root-finding with secant method Arguments ---------- callable, continuous function x0: float, initial seed float, initial seed float, target value iterations: int, maximum number iterations avoid indefinite divergence margin: float, margin error absolute term Return Values ---------- float where f(x2) within margin assert "Two different initial seeds required." abs((y0 f(x0) margin: found! return abs((y1 f(x1) margin: found! return range(iterations): x0) y0) abs((y2 f(x2) margin: found! return y0, return Explanation: above snippet code, have defined function secantAlgorithm that accepts some parameters like iterations, margin where callable, continuous function, float values initial seeds, again float value, target value, iterations integer value stores value maximum number iterations avoid indefinite divergence, margin margin error absolute term also float value. have then used assert keyword check value equals value x1. have then used conditional statement check y0 assigned f(x0) less than margin variable returns variable same. have again used conditional statement check assigned f(x1) less than margin variable returns variable same. last, have used for-loop iterate through values stored iterations variable defined formula find roots. Within loop, have again used conditional statement return x2. Understanding Steffensen's Method Secant's method further improves Regula Falsi algorithm eliminating requirements bracket consisting root. recall that straight line only na√Øve value tangent line (that derivative) values upper lower bound case Regula Falsi Illinois algorithm). This value will perfect search converges. Steffensen's algorithm, will attempt replace straight line with better value derivative further improving Secant's method. Strength: Steffensen's method does need bracket consisting root. This method also does need knowledge estimated area root. This method shows faster convergence than Secant's method possible. Weakness: Steffensen's method does give assurance convergence initial seed away from real root. continuous function will evaluated twice that Secant's method better calculate derivative. estimate derivative better with help Steffensen's Algorithm computing following based user-defined initial seed x0. Which equivalent following where f(x): Take limit will derivative ?(?). will then generalized evaluated slope function locate next step following same procedure Secant's method: consider following snippet code demonstrating same: Example: steffensenAlgorithm(f, iterations, margin .00_001): Iterative approach Root-finding with steffensen's method Arguments ---------- callable, continuous function float, initial seed float, target value iterations: int, maximum number iterations avoid indefinite divergence margin: float, error margin absolute term Return Values ---------- float where f(x2) within margin assert "Initial seed can't zero." abs((yx f(x) margin: found! return range(iterations): (f(x yx) Division zero, search stops return (f(x) abs((yx f(x) margin: found! return return Explanation: above snippet code, have defined function secantAlgorithm that accepts some parameters like iterations, margin where callable, continuous function, float values initial seeds, again float value, target value, iterations integer value stores value maximum number iterations avoid indefinite divergence, margin margin error absolute term also float value. have then used assert keyword check initial seed equal zero. have then used conditional statement check assigned f(x) less than margin variable returns variable same. last, have used for-loop iterate through values stored iterations variable defined formula find roots. Within loop, have again used conditional statement return Conclusion above tutorial, have understood strength, weakness, implementation following five algorithms used search root. Bisection Algorithm Regula Falsi Algorithm Illinois Algorithm Secant's Algorithm Steffensen's Algorithm consider following table showing comparison algorithms have implemented. Bisection Algorithm Regula Falsi Algorithm Illinois Algorithm Secant's Algorithm Steffensen's Algorithm Approach Bracket Bracket Bracket Iterative Iterative Convergence Guaranteed Guaranteed Guaranteed Guaranteed Guaranteed Knowledge Approximate Location Root Required Required Required Required Required Number Initial Seeds Risk Slow Convergence Available Stagnant Bound Available Initial Seed close enough Root Initial Seed close enough Root Method Reducing Problem Space Brute-force Halving Approximate Derivate with Finite Difference Approximate Derivate with Finite Difference Approximate Derivate with Finite Difference Approximate Derivate with Finite Difference Speed Convergence Linear Linear Super-linear Super-linear Quadratic Once comfortable with these algorithms, many other root-finding algorithms explore have been covered this tutorial. Some them Newton-Raphson's Method, Inverse Quadratic Interpolation, Brent's Method, more. Keep exploring above algorithms arsenal tools. Next TopicPython Module prev next