next prev Diabetes Prediction Using Machine Learning Diabetes medical disorder that impacts well body uses food fuel. Most food daily converted sugar, commonly known glucose, then discharged into bloodstream. pancreas releases insulin when blood sugar levels rise. Diabetes cause blood sugar levels rise continuously carefully managed, which raises chance severe side effects like heart attack stroke. therefore, choose forecast using Python machine learning. Steps Installing Libraries Importing Dataset Filling Missing Values Exploratory Data Analysis Feature Engineering Implementing Machine Learning Models Predicting Unseen Data Concluding Report Installing Libraries first have import most popular Python libraries, which will implementing machine learning algorithms first step building project, including Pandas, Seaborn, Matplotlib, others. will Python because most adaptable powerful programming language data analysis purposes. world software development, also Python. Code Import libraries import numpy linear algebra import pandas data processing, file (e.g. pd.read_csv) import seaborn data visualization import matplotlib.pyplot plot data visualization charts from collections import Counter import Modeling Libraries from sklearn.metrics import confusion_matrix, accuracy_score, precision_score from sklearn.preprocessing import QuantileTransformer from sklearn.linear_model import LogisticRegression from sklearn.neighbors import KNeighborsClassifier from sklearn.tree import DecisionTreeClassifier from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve, train_test_split from sklearn.svm import Sklearn toolkit incredibly practical helpful practical applications. offers vast selection models algorithms. Importing Dataset using Diabetes Dataset from Kaggle this study. National Institute Diabetes Digestive Kidney Diseases original source this database. Code Importing dataset from Kaggle data pd.read_csv("../input/pima-indians-diabetes-database/diabetes.csv") First step getting familiar with structure dataset data.info() Output <class 'pandas.core.frame.DataFrame'> RangeIndex: entries, 767 Data columns (total columns): Column Non-Null Count Dtype ------ -------------- ----- Pregnancies non-null int64 Glucose non-null int64 BloodPressure non-null int64 SkinThickness non-null int64 Insulin non-null int64 non-null float64 DiabetesPedigreeFunction non-null float64 non-null int64 Outcome non-null int64 dtypes: float64(2), int64(7) memory usage: 54.1 see, columns integers, except DiabetesPedigreeFunction. target variable labels with values person's diabetes status indicated zero. Code Showing rows dataset data.head() Output Pregnancies Glucose BloodPressure SkinThickness Insulin DiabetesPedigreeFunction Outcome 33.6 0.627 26.6 0.351 23.3 0.672 28.1 0.167 43.1 2.288 Filling Missing Values next step cleaning dataset, which crucial step data analysis. When modelling making predictions, missing data result incorrect results. Code Exploring missing values diabetes dataset data.isnull().sum() Output Pregnancies Glucose BloodPressure SkinThickness Insulin DiabetesPedigreeFunction Outcome dtype: int64 found missing values dataset, independent features like skin thickness, insulin, blood pressure, ;and glucose each have some values, which practically impossible. particular column's mean median scores must used replace unwanted values. Code Replacing values with mean that column Replacing values Glucose data['Glucose'] data['Glucose'].replace(0, data['Glucose'].median()) Filling values Blood Pressure data['BloodPressure'] data['BloodPressure'].replace(0, data['BloodPressure'].median()) Replacing values data['BMI'] data['BMI'].replace(0, data['BMI'].mean()) Replacing missing values Insulin SkinThickness data['SkinThickness'] data['SkinThickness'].replace(0, data['SkinThickness'].mean()) data['Insulin'] data['Insulin'].replace(0, data['Insulin'].mean()) data.head() Output Pregnancies Glucose BloodPressure SkinThickness Insulin DiabetesPedigreeFunction Outcome 35.000000 79.799479 33.6 0.627 29.000000 79.799479 26.6 0.351 20.536458 79.799479 23.3 0.672 23.000000 94.000000 28.1 0.167 35.000000 168.000000 43.1 2.288 Let's examine data statistics. Code Reviewing dataset statistics data.describe() Output Pregnancies Glucose BloodPressure SkinThickness Insulin DiabetesPedigreeFunction Outcome count 768.000000 768.000000 768.000000 768.000000 768.000000 768.000000 768.000000 768.000000 768.000000 mean 3.845052 121.656250 72.386719 26.606479 118.660163 32.450805 0.471876 33.240885 0.348958 3.369578 30.438286 12.096642 9.631241 93.080358 6.875374 0.331329 11.760232 0.476951 0.000000 44.000000 24.000000 7.000000 14.000000 18.200000 0.078000 21.000000 0.000000 1.000000 99.750000 64.000000 20.536458 79.799479 27.500000 0.243750 24.000000 0.000000 50% 3.000000 117.000000 72.000000 23.000000 79.799479 32.000000 0.372500 29.000000 0.000000 75% 6.000000 140.250000 80.000000 32.000000 127.250000 36.600000 0.626250 41.000000 1.000000 17.000000 199.000000 122.000000 99.000000 846.000000 67.100000 2.420000 81.000000 1.000000 dataset free missing unwanted values. Exploratory Data Analysis will demonstrate analytics using Seaborn this tutorial. Correlation Correlation relationship between more variables. Finding important features cleaning dataset before begin modelling also helps make model efficient. Code Correlation plot independent variables plt.figure(figsize (10, sns.heatmap(data.corr(), annot True, ".3f", cmap "YlGnBu") plt.title("Correlation heatmap") Output Observations show that characteristics like pregnancy, glucose, BMI, more closely associated with outcomes. demonstrated detailed illustration these aspects following phases. Pregnancy Code Exploring Pregnancy target variables together plt.figure(figsize (10, Plotting density function graph pregnancies target variable sns.kdeplot(data["Pregnancies"][data["Outcome"] color "Red", shade True) sns.kdeplot(data["Pregnancies"][data["Outcome"] kde, color "Blue", shade= True) kde.set_xlabel("Pregnancies") kde.set_ylabel("Density") kde.legend(["Positive Result", "Negative Result"]) Output According data, women having diabetes have given birth healthy infants. However, risk future complications decreased managing diabetes. risk pregnancy issues, such hypertension, depression, preterm birth, birth abnormalities, pregnancy loss, increased women have uncontrolled diabetes. Glucose Exploring Glucose Target variables together plt.figure(figsize (10, sns.violinplot(data data, "Outcome", "Glucose", split True, inner "quart", linewidth Output likelihood developing diabetes gradually climbs with glucose levels. Code Exploring density function plot Glucose levels plt.figure(figsize (10, sns.kdeplot(data["Glucose"][data["Outcome"] color "Red", shade True) sns.kdeplot(data["Glucose"][data["Outcome"] kde, color "Blue", shade= True) kde.set_xlabel("Glucose") kde.set_ylabel("Density") kde.legend(["Positive Result","Negative Result"]) Output Implementing Machine Learning Models will test many machine learning models compare their accuracy this part. After that, will tune hyperparameters models with good precision. will sklearn.preprocessing convert data into quantiles before dividing dataset. Code Transforming data into quartiles quartile QuantileTransformer() quartile.fit_transform(data) dataset quartile.transform(X) dataset pd.DataFrame(X) dataset.columns =['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'] Showing rows transformed dataset dataset.head() Output Pregnancies Glucose BloodPressure SkinThickness Insulin DiabetesPedigreeFunction Outcome 0.747718 0.810300 0.494133 0.801825 0.380052 0.591265 0.750978 0.889831 0.232725 0.091265 0.290091 0.644720 0.380052 0.213168 0.475880 0.558670 0.863755 0.956975 0.233377 0.308996 0.380052 0.077575 0.782269 0.585398 0.232725 0.124511 0.290091 0.505867 0.662973 0.284224 0.106258 0.000000 0.000000 0.721643 0.005215 0.801825 0.834420 0.926988 0.997392 0.606258 Data Splitting will divide data into training testing dataset. will training testing datasets train evaluate different models. will also perform cross-validation multiple models before predicting testing data. Code Splitting dependent independent features data.drop(["Outcome"], axis data["Outcome"] Splitting dataset into training testing dataset X_train, X_test, Y_train, Y_test train_test_split(X, test_size 0.40, random_state Printing size training testing dataset print("The size training dataset: X_train.size) print("The size testing dataset: X_test.size) Output size training dataset: 3680 size testing dataset: 2464 above code splits dataset into train (70%) test (30%) datasets. Cross Validate Models will perform cross-validation models. Code Python program create function validate models cv_model(models): will create list machine learning models print graphs cross-validation scores with help mean accuracy. Cross validating model using Kfold stratified cross-validation method k_fold StratifiedKFold(n_splits models r.append(cross_val_score(estimator X_train, Y_train, scoring "accuracy", k_fold, n_jobs cross_val_means cross_val_std result cross_val_means.append(result.mean()) cross_val_std.append(result.std()) df_result pd.DataFrame({ "CrossValMean": cross_val_means, "CrossValStd": cross_val_std, "Model List":[ "DecisionTreeClassifier", "LogisticRegression", "SVC", "AdaBoostClassifier", "GradientBoostingClassifier", "RandomForestClassifier", "KNeighborsClassifier" Generating graph cross-validation scores bar_plot sns.barplot(x cross_val_means, df_result["Model List"].values, data df_result) bar_plot.set_xlabel("Mean Cross Validation Accuracy Scores") bar_plot.set_title("Cross Validation Scores Models") return df_result list machine learning models passed 'cv_model' function, which provides graph cross-validation scores based mean accuracy values various models supplied function. Code Modeling dataset using different machine learning algorithms state models_list DecisionTreeClassifier(random_state state), LogisticRegression(random_state state, solver ='liblinear'), SVC(random_state random_state), AdaBoostClassifier(DecisionTreeClassifier(random_state state), random_state state, learning_rate 0.3), GradientBoostingClassifier(random_state state), RandomForestClassifier(random_state state), KNeighborsClassifier() cv_model(models_list) Output CrossValMean CrossValStd Model List 0.697921 0.067773 DecisionTreeClassifier 0.780358 0.085376 LogisticRegression 0.782437 0.069578 0.686882 0.050551 AdaBoostClassifier 0.762796 0.072912 GradientBoostingClassifier 0.760717 0.079104 RandomForestClassifier 0.739283 0.043985 KNeighborsClassifier According above analysis, have discovered that RandomForestClassifier, LogisticRegression, models have higher accuracy. will therefore perform hyperparameter tuning these three different models. Hyperparameter Tuning Selecting best collection hyperparameters machine learning algorithm known hyperparameter tuning. model input called hyperparameter value predetermined before learning phase even starts. Hyperparameter tuning essential machine learning models work. have individually tuned RandomForestClassifier, LogisticRegression, models. Code Importing required libraries from sklearn.metrics import classification_report from sklearn.model_selection import GridSearchCV Defining function analyse grid results analyze_grid(grid): Analyzing results GridCV method making predictions test data Presenting classification report Printing best parameter accuracy score print("Tuned hyperparameters: grid.best_params_) print("Accuracy Score:", grid.best_score_) mean_values grid.cv_results_["mean_test_score"] std_values grid.cv_results_["std_test_score"] zip(mean_values, std_values, grid.cv_results_["params"]): print(f"Mean: {m}, Std: {s} Params: {p}") print("The classification Report:") Y_true, Y_pred Y_test, grid.predict(X_test) print(classification_report(Y_true, Y_pred)) print() GridSearchCV classification report classes firstly imported from Sklearn package. "analyse grid" method, which will display predicted result, then defined. have invoked this method each model utilised SearchCV. will tune each model following stage. Tuning Hyperparameters LogisticRegression Code Defining Logistic Regression model parameters model LogisticRegression(solver ='liblinear') solver_list ['liblinear'] penalty_type ['l2'] c_values [200, 100, 1.0, 0.01] Defining grid search grid_lr dict(solver solver_list, penalty penalty_type, c_values) cross_val StratifiedKFold(n_splits 100, random_state shuffle True) grid_search_cv GridSearchCV(estimator model, param_grid grid_lr, cross_val, scoring 'accuracy', error_score lr_result grid_search_cv.fit(X_train, Y_train) Result Hyper Parameters Logistic Regression analyze_grid(lr_result) Output Tuned hyperparameters: {'C': 200, 'penalty': 'l2', 'solver': 'liblinear'} Accuracy Score: 0.7715000000000001 Mean: 0.7715000000000001, Std: 0.16556796187668676 Params: {'C': 200, 'penalty': 'l2', 'solver': 'liblinear'} classification Report: Mean: 0.7715000000000001, Std: 0.16556796187668676 Params: {'C': 100, 'penalty': 'l2', 'solver': 'liblinear'} classification Report: Mean: 0.7675, Std: 0.16961353129983467 Params: {'C': 'penalty': 'l2', 'solver': 'liblinear'} classification Report: Mean: 0.7675, Std: 0.17224619008848932 Params: {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'} classification Report: Mean: 0.711, Std: 0.1888888562091475 Params: {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'} classification Report: precision recall f1-score support 0.78 0.88 0.83 0.70 0.53 0.61 accuracy 0.76 macro 0.74 0.71 0.72 weighted 0.75 0.76 0.75 output, best score returned LogisticRegression model 0.77 with {'C': 200, 'penalty': 'l2', 'solver': 'liblinear'} parameters. Similarly, will perform parameter tuning other models. Tuning Hyperparameters Code Defining model parameters Defining grid search SVC() parameters {"kernel": ["rbf"], "gamma": [1e-4], "C": [200, 100, 1.0, 0.01]} Performing cross-validation with tuned parameters cross_val StratifiedKFold(n_splits random_state shuffle True) Performing grid search grid GridSearchCV(estimator svc, param_grid parameters, cross_val, scoring 'accuracy') Hyperparameter tuning result result grid.fit(X_train, Y_train) analyze_grid(result) Output Tuned hyperparameters: {'C': 1.0, 'gamma': 0.0001, 'kernel': 'rbf'} Accuracy Score: 0.7695158871629459 Mean: 0.745607333842628, Std: 0.019766615171568313 Params: {'C': 200, 'gamma': 0.0001, 'kernel': 'rbf'} classification Report: Mean: 0.7521291344820756, Std: 0.02368565638376449 Params: {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'} classification Report: Mean: 0.7542370483546955, Std: 0.046474062764375476 Params: {'C': 'gamma': 0.0001, 'kernel': 'rbf'} classification Report: Mean: 0.7695158871629459, Std: 0.016045599935252022 Params: {'C': 1.0, 'gamma': 0.0001, 'kernel': 'rbf'} classification Report: Mean: 0.650001414707297, Std: 0.002707677330225552 Params: {'C': 0.01, 'gamma': 0.0001, 'kernel': 'rbf'} classification Report: precision recall f1-score support 0.74 0.88 0.80 0.64 0.42 0.51 accuracy 0.72 macro 0.69 0.65 0.66 weighted 0.71 0.72 0.70 Model's maximum accuracy 0.769, somewhat less than that Logistic Regression. leave this model here only. Tuning Hyperparameters RandomForestClassifier Code Defining model parameters Defining grid search RandomForestClassifier(random_state parameters 'n_estimators': [500], 'max_features': ['log2'], 'max_depth' [4,5,6], 'criterion' :['entropy'] Performing cross-validation with tuned parameters cross_val StratifiedKFold(n_splits random_state shuffle True) Performing grid search grid GridSearchCV(estimator rfc, param_grid parameters, cross_val, scoring 'accuracy') Hyperparameter Tuning Result result grid.fit(X_train, Y_train) analyze_grid(result) Output Tuned hyperparameters: {'criterion': 'entropy', 'max_depth': 'max_features': 'log2', 'n_estimators': 500} Accuracy Score: 0.7717369776193306 Mean: 0.7673938262173556, Std: 0.0027915297477680364 Params: {'criterion': 'entropy', 'max_depth': 'max_features': 'log2', 'n_estimators': 500} classification Report: Mean: 0.7717369776193306, Std: 0.005382324516419591 Params: {'criterion': 'entropy', 'max_depth': 'max_features': 'log2', 'n_estimators': 500} classification Report: Mean: 0.7652151769798828, Std: 0.02135846347536185 Params: {'criterion': 'entropy', 'max_depth': 'max_features': 'log2', 'n_estimators': 500} classification Report: precision recall f1-score support 0.76 0.87 0.81 0.66 0.50 0.57 accuracy 0.74 macro 0.71 0.68 0.69 weighted 0.73 0.74 0.73 Predicting Unseen Data have spent time working Exploratory Data Analysis, cross-validation machine learning algorithms, hyperparameter tuning identify best model that fits dataset. will make predictions using model tuned hyperparameters with highest accuracy score. Code Making predictions Y_pred lr_result.predict(X_test) print(classification_report(Y_test, Y_pred)) Output precision recall f1-score support 0.78 0.88 0.83 0.70 0.53 0.61 accuracy 0.76 macro 0.74 0.71 0.72 weighted 0.75 0.76 0.75 Finally, append feature column test dataset called Prediction print dataset. Code X_test['predictions'] Y_pred print(X_test) Output Concluding Report risks during pregnancy diabetes. will have diagnosed avoid problems. increase glucose levels strongly correlated rise diabetes. Logistic Regression with tuned parameters given maximum accuracy score. Next TopicFirst Unique Character String Python prev next