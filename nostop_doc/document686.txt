next prev Sklearn Linear Regression Example machine learning algorithm built supervised learning called linear regression. executes regression operation. Regression uses independent variables train model find prediction values, mainly used determine variables predictions relate another. Regression models vary according number independent variables use, relationship they consider between dependent independent variables, other factors. This tutorial will show apply linear regression given dataset using several Python modules. Since single linear model simpler visualise, we'll example. model will sklearn diabetes dataset this presentation learn. Linear Regression Sklearn? Python package called Scikit-learn simplifies using various Machine Learning (ML) methods studying predictive data, including linear regression. Finding straight line model that best fits collection scattered data points known linear regression; then extrapolate curve foretell data points. Linear regression vital Machine Learning technique simplicity characteristics. Linear Regression using Sklearn Example Code Python code sklearn linear regression example Importing required libraries import numpy import matplotlib.pyplot from sklearn.datasets import load_diabetes from sklearn.linear_model import LinearRegression from sklearn.model_selection import train_test_split from sklearn.metrics import mean_squared_error, r2_score Loading sklearn diabetes dataset load_diabetes(return_X_y=True) Taking only feature perform simple linear regression X[:,8].reshape(-1,1) Splitting dependent independent features dataset into training testing dataset X_train, X_test, Y_train, Y_test train_test_split( test_size 0.3, random_state Creating instance linear regression model sklearn linear_model.LinearRegression() Training model passing dependent independent features training dataset lr.fit( X_train, Y_train Creating array predictions made model unseen test dataset Y_pred lr.predict( X_test value coefficients independent feature through multiple regression model print("Value oefficients: \n", lr.coef_) value mean squared error print(f"Mean square error: {mean_squared_error( Y_test, Y_pred)}") value coefficient determination, i.e., R-square score model print(f"Coefficient determination: {r2_score( Y_test, Y_pred )}") Plotting output plt.scatter(X_test, Y_test, color "black", label "original data") plt.plot(X_test, Y_pred, color "blue", linewidth=3, label "regression line") plt.xlabel("Independent Feature") plt.ylabel("Target Values") plt.title("Simple Linear Regression") plt.show() Output: Value coefficients: [875.72247876] Mean square error: 4254.602428877642 Coefficient determination: 0.3276195356900222 Sklearn Linear Regression Example Using Cross-Validation Many models trained portions data then evaluated complementing subset data. This process known cross-validation. identify overfitting fail generalise pattern, cross-validation. Cross-validation involves following three steps: aside certain amount sample data set. Train model using specific portion dataset. Validate model using data set's reserve section. generate multiple small train-test splits using original training dataset through cross-validation. these splits train model, which best describes relationship between dependent independent variables. standard k-fold cross-validation test, split original dataset into subgroups. After have trained linear regression model iteratively using dataset, remaining dataset validate model. This allows validate model dataset know model describes good relationship not. this section, we'll learn cross-validation tests linear regression model using sklearn. Additionally, will method improve accuracy provided KFold cross-validation method. Code Python program perform kfold cross-validation test Linear Regression model #Importing required libraries from sklearn.datasets import load_diabetes import pandas from sklearn.linear_model import LinearRegression from sklearn.model_selection import KFold from sklearn.model_selection import cross_val_score from sklearn.model_selection import train_test_split #Loading diabetes dataset sklearn dataset load_diabetes(as_frame True) dataset data.frame Segregating dependent independent variables dataset dataset.iloc[:,:-1] dataset.iloc[:,-1] Separating dataset into training testing dataset X_train, X_test, Y_train, Y_test train_test_split(X, test_size 0.3) #Implementing k-fold cross validation k_value k_fold KFold(n_splits k_value, random_state None) Lreg LinearRegression() Fitting Linear Regression model training dataset Lreg.fit(X_train, Y_train) Finding accuracy scores each fold using cross_val_score methods scores cross_val_score(Lreg, X_train, Y_train, k_fold) Calculating mean accuracy score through scores value mean_accuracy_score sum(scores) len(scores) Printing accuracy scores print("Accuracy score each fold: scores) print("Mean accuracy score: mean_accuracy_score) Output: Accuracy score each fold: [0.41676766 0.45263441 0.44526044 0.43015152 0.40605028 0.41904005] Mean accuracy score: 0.4283173940888665 improve accuracy KFold cross-validation test, stratified KFold method Code Python program showing stratified k-fold cross-validation test Linear Regression model Importing required library from sklearn.datasets import load_diabetes from sklearn.linear_model import LinearRegression from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split Loading dataset dataset load_diabetes() Getting dependent independent features dataset.data dataset.target print("Size dataset len(X)) Separating dataset into training testing dataset X_train, X_test, Y_train, Y_test train_test_split(X, test_size 0.3) Creating instance linear regression model Lreg LinearRegression() Fitting training dataset train model Lreg.fit(X_train, Y_train) Performing stratified K-fold cross-validation test stratified_kfold StratifiedKFold(n_splits score cross_val_score(Lreg, stratified_kfold Printing accuracy scores print("Stratified k-fold Cross Validation Scores are: score print("Average Cross Validation score score.mean()) Output: Size dataset 442 Stratified k-fold Cross Validation Scores are: [0.50117449 0.45486492 0.46935982 0.5599043 0.50545775 0.42289802] Average Cross Validation score 0.48560988266624 Multivariate Linear Regression Using Python Sklearn supervised machine learning approach called multivariate regression used many independent data features analyse target feature. dependent variable many independent variables make multivariate regression, which elaboration multiple regression models. attempt forecast result training model using independent variables. Multivariate regression uses formula describe several variables react concurrently changes target variable. Data Pre-processing Most programmers believe that data pre-processing among most crucial phases regression model project. There excessive data points, reporting mistakes, many other problems that prevent algorithm from making accurate prediction dataset. Before dataset ever into model, data scientists spend numerous hours cleaning, normalising, scaling data avoid this. Standardizing functions, such MinMax Standard functions, most frequent function types perform feature scaling. This range features your data. Euclidean distance used almost machine learning methods estimate separation between data points. scaling every point collection within same range, scale standardization functions enable algorithms calculate distance accurately. must first import sklearn.preprocessing numpy both. Multiple Linear Regression Sklearn example Code Python program shows process data before fitting Linear Regression Model. Multiple Linear Regression Sklearn example Importing required libraries import numpy import pandas import matplotlib.pyplot from sklearn import preprocessing from sklearn.datasets import load_iris from sklearn.model_selection import train_test_split from sklearn.linear_model import LinearRegression Loading dataset iris_data datasets.load_iris() dataset pd.DataFrame(data iris_data.data, columns iris_data.feature_names) Adding target feature dataset dataset["target"] iris_data.target #Printing head dataset print(dataset.head()) Eliminating from dataset missing type input numbers dataset.fillna(method 'ffill', inplace True) Dropping rows with values dataset.dropna(inplace True) Separating independent dependent variables This will convert each dataframe into numpy arrays dataset.iloc[:, :-1].values dataset.iloc[:, -1].values Separating data into training test data X_train, X_test, Y_train, Y_test train_test_split(X, test_size 0.25, random_state Creating instance Linear Regression class sklearn LinearRegression() Fitting training data dataset into model train model lr.fit( X_train, Y_train Printing R-square trained model passing unseen test data score lr.score( X_test, Y_test print("R-square score model: score) Storing predicted values test dataset model array Y_pred lr.predict(X_test) Creating dataset coefficient value intercept independent features result pd.DataFrame(data dataset.iloc[:,:-1].columns, columns ["Features"]) result["Coefficients"] lr.coef_ result.loc[0] ["Intercept", lr.intercept_] result Output: sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) target R-square score model: 0.9215461211058802 	Features	Coefficients 0	Intercept	0.279851 1	sepal width (cm)	-0.006845 2	petal length (cm)	0.297868 3	petal width (cm)	0.507009 Next TopicPython Timeit Module prev next