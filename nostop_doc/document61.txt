next prev Grid Search Python this tutorial, will discuss Grid Search purpose hyperparameter tuning. will also learn about working Grid Search along with implementation optimizing performance method Machine Learning (ML). Hyperparameter tuning significant appropriate working models Machine Learning (ML). method like Grid Search appears basic utility hyperparameter optimization. Grid Search Method considers some hyperparameter combinations selects returning lower error score. This method specifically useful when there only some hyperparameters order optimize. However, outperformed other weighted-random search methods when Machine Learning model grows complexity. begin understanding Grid Search. Understanding Grid Search Grid Search optimization algorithm that allows select best parameters optimize issue from list parameter choices providing, thus automating 'trial-and-error' method. Although apply multiple optimization issues; however, most commonly known utilization machine learning order obtain parameters which model provides best accuracy. consider that model accepts below three parameters form input: Number hidden layers Number neurons every layer Number epochs [10, want options every parameter input specified square brackets above), estimates different combinations. instance, possible combination 10]. Finding such combinations manually would headache. Now, suppose that different parameters input, would like five possible values each every parameter. would need manual input from programmer's every time like alter value parameter, re-execute code, keep record outputs every combination parameters. Grid Search automates that process, accepts possible value every parameter executes code order each every possible combination outputs result combinations outputs combination having best accuracy. Installing required libraries Before start implementing Grid Search Python programming language, briefly discuss some necessary libraries frameworks that need installed system. These libraries frameworks follows: Python NumPy Pandas Keras Scikit-Learn They quite simple install. installer order install these libraries shown below: install numpy tensorflow pandas scikit-learn keras Note: issues arise while executing package, reinstalling referring each package's official documentation. Now, begin implementing Grid Search Python Implementation Grid Search Python following section, will understand implement Grid Search actual application. will simply executing code discuss in-depth regarding section where Grid Search comes rather than discussing Machine Learning Data Pre-processing section. let's started. will Diet Dataset containing data regarding height weight different people based various attributes such gender, age, type diet. directly import data from online resource with help Pandas read_csv() function. before that, have import required packages: File: mygrid.py import import pandas import numpy from sklearn.model_selection import GridSearchCV, KFold from keras.models import Sequential from keras.layers import Dense, Dropout from keras.wrappers.scikit_learn import KerasClassifier from keras.optimizers import Adam Explanation: above snippet code, have imported required packages libraries necessary project. also save program file execute order check libraries packages installed imported properly. Once packages imported successfully, have following snippet code order import dataset print first five rows File: mygrid.py importing dataset mydf pd.read_csv("Diet_Dataset.csv") printing first five lines dataset print(mydf.head()) Output: Person gender Height pre.weight Diet weight6weeks 60.0 103.0 54.2 54.0 63.3 Explanation: above snippet code, have imported dataset using read_csv() pandas library stored within mydf variable. have then printed first five rows using head() function along with mydf variable. Now, divide data into feature label sets order apply standard scaling dataset. snippet code same shown below: File: mygrid.py converting dataframe into numpy array mydataset mydf.values mydataset[:, 0:6] mydataset[:, 6].astype(int) Normalizing data using sklearn StandardScaler from sklearn.preprocessing import StandardScaler myscaler StandardScaler().fit(X) Transforming displaying training data X_stdized myscaler.transform(X) mydata pd.DataFrame(X_stdized) Explanation: above snippet code, have converted pandas dataframe into NumPy array. have then imported StandardScaler module from sklearn library function normalize data. have then transformed displayed training data using transform() function. Now, consider following snippet code order create simple deep learning model. File: mygrid.py defining function create model create_my_model(learnRate, dropoutRate): Creating model mymodel Sequential() mymodel.add(Dense(6, input_dim kernel_initializer 'normal', activation 'relu')) mymodel.add(Dropout(dropoutRate)) mymodel.add(Dense(3, input_dim kernel_initializer 'normal', activation 'relu')) mymodel.add(Dropout(dropoutRate)) mymodel.add(Dense(1, activation 'sigmoid')) Compiling model my_Adam Adam(learning_rate learnRate) mymodel.compile(loss 'binary_crossentropy', optimizer my_Adam, metrics ['accuracy']) return mymodel Explanation: following snippet code defined function create_my_model() accepting parameters, i.e., learnRate dropoutRate, respectively. have then created model mymodel using Sequential() function. have also used add() along with Dense() Dropout() function. have then compiled model using compile() function. result, when execute code, this will lead loading dataset, preprocessing creating machine learning model. Since only interested understanding working Grid Search, haven't performed train/test split, fitted model complete dataset. Now, will understand Grid Search makes programmer's life easier optimizing parameters next section. Training Model without Grid Search snippet code shown below, will create model with help parameter values that decided randomly based intuition model performs: File: mygrid.py Declaring values parameter dropoutRate epochs batchSize learnRate 0.001 Creating model object calling create_my_model function created above mymodel create_my_model(learnRate, dropoutRate) Fitting model onto training data mymodel.fit(X_stdized, batch_size batchSize, epochs epochs, verbose Output: 4/4 [==============================] 41s 14ms/step loss: 0.9364 accuracy: 0.0000e+00 Explanation: above snippet code, have declared values parameter, i.e., dropoutRate, epochs, batchSize, learnRate, respectively. have then created model object calling create_my_model() function. have then fitted model onto training data. result, accuracy 0.0000e+00. Optimizing Hyper-parameters using Grid Search using Grid Search method, directly call fit() function model have created above. order utilize Grid Search method, have pass arguments create_my_model() function. Moreover, have declare grid with various options every parameter. perform that different parts. First all, will modifying create_my_model() function order accept arguments from calling function shown below: File: mygrid.py create_my_model(learnRate, dropoutRate): Creating model mymodel Sequential() mymodel.add(Dense(6, input_dim kernel_initializer 'normal', activation 'relu')) mymodel.add(Dropout(dropoutRate)) mymodel.add(Dense(3, input_dim kernel_initializer 'normal', activation 'relu')) mymodel.add(Dropout(dropoutRate)) mymodel.add(Dense(1, activation 'sigmoid')) Compile model myadam Adam(learning_rate learnRate) mymodel.compile(loss 'binary_crossentropy', optimizer myadam, metrics ['accuracy']) return mymodel Creating model object mymodel KerasClassifier(build_fn create_my_model, verbose Explanation: above snippet code, have made some changes previous create_my_model function used KerasClassifier create model object. Now, implement algorithm Grid Search dataset File: mygrid.py Defining arguments that want Grid Search along with list values that want learnRate [0.001, 0.02, 0.2] dropoutRate [0.0, 0.2, 0.4] batchSize [10, epochs Making dictionary grid search parameters paramgrid dict(learnRate learnRate, dropoutRate dropoutRate, batch_size batchSize, epochs epochs Building fitting GridSearchCV mygrid GridSearchCV(estimator mymodel, param_grid paramgrid, KFold(random_state None), verbose gridresults mygrid.fit(X_stdized, Summarizing results readable format print("Best: gridresults.best_score_ using gridresults.best_params_) means gridresults.cv_results_['mean_test_score'] stds gridresults.cv_results_['std_test_score'] params gridresults.cv_results_['params'] mean, stdev, param zip(means, stds, params): print(mean stdev with: param) Output: Best: 0.00347268912077, using {batch_size=10, dropoutRate=0.4, epochs=5, learnRate=0.2} Explanation: above output shows parameter combination which yields best accuracy. last, conclude that Grid Search quite easy implement Python programming language saved time human labor. list down arguments wanted tune, declare values that need tested, execute code, forget about process easy convenient that requires less input from programmer's side. Once best argument combination been found, utilize that final model. Next TopicPython High Order Function prev next