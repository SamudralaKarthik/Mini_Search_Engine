next prev Speech Recognition python Have ever thought about Google Assistant Amazon Alexa recognizes whatever say? must thinking about some complex smart technologies working behind bars. Apart from massive market tremendous technological growth recognition systems, majority cellular device feature speech recognition through some inbuilt applications third party applications. necessarily; most such speech recognition systems built deployed with help python packages libraries. certain level, Python proven that essential aspect foreseeable future. reason pretty obvious. incorporate speech recognition Python, need certain level interactivity accessibility match technologies. concept accessibility worth considering because recognition allows elderly, physically challenged, visually impaired humans interact with machines solve their problems with state-of-the-art services products quickly without choosing random applications. this article, you'd learning create speech recognition system Python. ease process understanding built, this article designed teach build system with less effort more enthusiasm. before moving into project, let's talk about some more important aspects know developer. Overview- works Before moving into nooks complications project, will build take moment understand nitty-gritty overview about working speech recognition. Although there pre-requisites started, good know fundamentals python programming language. Speech recognition evolved from research conducted Bell Labs back 1950 with limitations just single speaker limited vocabulary database. Modern speech recognition applications have come long ever since onset ancient counterparts. Talking about components speech, first component speech. must converted from sound signal that travel through microphone transcribed digital data. This done using analog digital converter. Once form data digitized, several trained models easily transcribe audio text. Modern-day speech recognizer relies less-known concept Hidden Markov Model (HMM). approach based assumptions formulated speech signal when persists short period (say five milliseconds) possibly termed stationary process, i.e., process based statistics that don't change over time. typical HMM, default signal division speech about milliseconds divided into various fragments. power spectrum each fragment helps signals plot function generate frequency that later mapped vector real numbers called cepstral coefficients. dimensions mapped vector quite small, compared some accurate systems that have dimensions touching more. generated final output HMM comes form vector sequences. Group vectors plays important role decoding speech into text with help phonemes which fundamental units speech. calculation phonemes depends training since there speaker variations, even same speaker, utterance different sometimes. Therefore, cope with this issue, special algorithm considered that determines most relative words producing phoneme sequence. whole process that just learned quite expensive terms computation. Neural Networks used transform features dimensions modern speech recognition systems, reducing need HMM. Additionally, Voice Activity Detectors (VAD) also used reduce some portion audio signal that might contain some speech. mainly used recognize unnecessary parts speech stop them from being taken into consideration. Speech Recognition Packages There handful packages speech recognition that exist chain PyPI. Some them are: Assembly Apia SpeechRecognition Wit Watson-developer-cloud above-given packages, such apiai wit, offer feature like natural language processing. Their in-built feature helps identify speaker's intent goes beyond generic speech recognition. Other packages primarily focus speech-to-text conversion. Only package that stands from above-given packages SpeechRecognition. Recognizing speech needs some input form audio, SpeechRecognition package retrieves these kinds input effortlessly. needs hardcore scripts access microphones then process audio from scratch. Another advantage this package that will save your time minutes execute instructions. SpeechRecognition library behaves like cover wrapper various APIs solely built speech. tremendously flexible agile. such Google Speech that supports hard-coded default speech recognition. SpeechRecognition library super easy use, package easy imported python project. also important note that this package wrap APIs available today. Thus, need identify exactly what kind package need build your speech recognizer. might have theoretically understood strengths flaws some speech recognizers overview speech Recognizer works, let's proceed with installation SpeechRecognition package into local environment using installation procedures given below. SpeechRecognition Installation SpeechRecognition package compatible with various versions python language like 2.6, 2.7, 3.3+. also need some other installations your python version old. Assuming that have Python 3.3+ version your local system, carry your installation methods from terminal with pip. install SpeechRecognition After installation, must verify installation properly interpreted using following code given below. import speech_recognition sr._version_'3.8.1' SpeechRecognition work exceptionally well working with audio files package. However, might also need some dependencies. Therefore, ease this process, PyAudio package comes handy capturing inputs from microphone. Recognizer Class magic SpeechRecognition comes into play only presence Recognizer class. main purpose Recognizer recognize speech along with reading variations different speeches then driving functionalities validating speech coming from audio source. create Recognizer, need create instance. type below code python interpreter. r=sr.Recognizer() There various methods create Recognizer instances that recognize speech from audio source with support. Some them enlisted below. recognize_bing(): Microsoft Bing Speech recognize_google(): Google Speech recognize_google_cloud(): Google Cloud Speech requires installation google-cloud-speech package recognize_houndify(): Houndify SoundHound recognize_ibm(): Speech Text recognize_sphinx(): Sphinx requires installing PocketSphinx recognize_wit(): Wit.ai these packages, package recognize_sphinx() designed serve offline used with Sphinx Engine. rest packages need internet connectivity work. Note: important cautious about default provided SpeechRecognition. mainly used testing, security purposes, might revoked Google. Thus, SpeechRecognition interface that translate these default keys used with care. each_recognize_*() method might throw exception named speech_recognition.RequestError exception. This might happen because might unreachable because corrupt installation. rest methods shown above, RequestError might generated limits under their quota reached, server internet connection might issue. There might arise issue that looks something like this. Traceback (most recent call last): File "<stdin>", line <module> TypeError: recognize_google() missing required positional argument: 'audio_data' Functioning with Audio Files Before working with SpeechRecognition package Python, first need download audio file. SpeechRecognition makes easy work with audio files saving them same directory python interpreter currently running. does that using AudioFile class. This class needs initialized with audio file path that context manager provides good interface read files their contents. Supported File Types types file formats that SpeechRecognition supports given follows: WAV: format must PCM/LPCM AIFF AIFF-C FLAC: format must native FLAC have x-86 based Windows, Linux, macOS, easier work with FLAC files. Apart from these operating systems, need install FLAC encoder that gives access command-line tool. Capturing data using record() record() function used capture data from file using python interpreter your file. instance, file's name "harvard.wav", python interpreter code encoding this method will follows. hardvard sr.AudioFile('harvard.wav') with harvard source: Audio r.record(source) This code would open context manager read contents file will store data AudioFile instance known source. record() method then records real data from file. confirm whether data recorded, check using following code. type(audio) <class' speech_recognition.AudioData'> Alternatively, also invoke recognize_google() that audio recognized. depend your internet speed, audio captured, many seconds results displayed. r.recognize_google(audio) This code would transcribe data present file write recognized audio text format. Duration Segment offset Capturing Consider that want capture only particular segment speech file. record() method that recognizing duration keyword followed argument that stops speech after some seconds. instance, might need capture first seconds speech from "harvard.wav" file; this using following method given below. with harvard source: Audio r.record(source, duration=5) >r.recognize_google(audio) When used inside block, record() method always intends move ahead file stream. This usually means that recording happens again four seconds returns first four-second audio recording first four seconds. phenomenon illustrated with code snippet given below. with harvard source: audio1 r.record(source, duration=4) audio2 r.record(source, duration=4) r.recognize_google(audio1) 'the stale smell beer lingers' r.recognize_google(audio2) takes heat bring odor cold dip.' notice that audio2 contains part third phase audio. There also some instances where specify duration, recording stopped midway, which usually hurts audio's transparency. Additionally, while specifying record() method, even specific starting point using argument through offset keyword. starting point represents number seconds from file before recording started. Thus, capture second phrase from audio file, seconds seconds depending your need using below method. with harvard source: audio r.record(source, offset=4, duration=3) r.recognize_google(audio) importance duration offset keyword fall segmentation file containing audio. already know audio frames, hastily fall poor transcription results. visualize this effect, following code trying with python interpreter. with harvard source: audio r.record(source, offset=4.7, duration=2.8) r.recognize_google(audio) above code snippet states that recording starts seconds beginning phrase will missed. Similarly, when recording ends, captured phrase will match beginning phase. Another reason missing phrases that resulting inaccurate transcription Noise. above might work well because clean audio, there's such place without Noise real world. Effects Noise Speech Recognition place Noise free. speech recognition techniques have been developed address remove unwanted Noise present speech that dampens power capturing audio frames. Noise wreck precision applications. understand Noise impacts speech recognition, need download file named "jackhammer.wav" ensure save your working directory interpreter. Assuming that this file phrase "JavaTpoint best java training site" spoken loudly, need transcribe background. that, consider below method. jackhammer sr.AudioFile('jackhammer.wav') with jackhammer source: audio r.record(source) r.recognize_google(audio) deal with Noise, another method after above step using method adjust_for_ambient_noise() Recognizer class. with jackhammer source: r.adjust_for_ambient_noise(source) audio r.record(source) r.recognize_google(audio) above code snippet misses initial output, output printed without first word. Hence, when record() method captures audio, first portion audio file consumed, later data captured. adjust_for_ambient_noise() method reads first second audio file Recognizer calibrates noise level audio. want adjust time frame using adjust_for_ambient_noise(), duration keyword your code snippet assigning numerical value seconds. don't assign value, taken default value, recommended lower value 0.5. following code snippet shows same technique. with jackhammer source: r.adjust_for_ambient_noise(source, duration=0.5) audio r.record(source) r.recognize_google(audio) above code snippet will return whole audio file that previously missed beginning. Although, there some cases where very difficult handle remove effect Noise because signal possibly noisy deal with. Therefore, have resort some other techniques pre-process audio deal with such issue. that, audio editing software Python package like SciPy. package pre-process audio file filter Noise. Additionally, while working with noisy files, helpful that actual response since most return JSON strings that have many transcriptions. Similarly, recognize_google() method bound deliver similar transcripted files unless forced deliver full response. This method practically implemented using certain arguments keywords like show_all that returns recognize_google() method. r.recognize_google(audio, show_all=True) {'alternative': {'transcript': 'javatpoint best programming site'}, {'transcript': 'the javatpoint site best programming'}, {'transcript': 'javatpoint programming best site'}, {'transcript': 'the programming javatpoint best site'}, {'transcript': 'best programming site javatpoint'}, 'final': True} above code snippet, recognize_google() method returns dictionary with alternative that points various transcriptions shown above. Although response structure have different forms because variations from API, this primarily used debugging. now, might have learned basics speech recognition package Python. next phase learning involves transcribing audio files making project little more interactive taking input from microphone. Working with microphone input access your microphone using SpeechRecognizer package installing package named PyAudio. that, save changes close interpreter. ahead install PyAudio with similar process with SpeechRecognizer. install pyaudio After installation, test whether compatible with version speech Recognizer using, type below command. python speech_recognizer After this step, need ensure that your default microphone turned unmuted. didn't face problem installation testing, should something like this terminal. moment silence, please? minimum energy threshold 600.4452854381937 something! playing with seeking into microphone testing SpeechRecognizer package transcribes your speech. Microphone Class microphone class used create instance system recognize audio file from source. this class, need import opening another interpreter session creating recognizer class, shown below. import speech_recognizer r.=sr.Recognizer() need default microphone system instead using audio file from source. that using method shown. sr.Microphone() cannot recognize default microphone your system, need specify device indexes. list available microphone names using list_microphone_names() method microphone class. sr.Microphone.list_microphone_names() ['HDA Intel PCH: ALC272 Analog (hw:0,0)', 'HDA Intel PCH: HDMI (hw:0,3)', 'sysdefault', 'front', 'surround40', 'surround51', 'surround71', 'hdmi', 'pulse', 'dmix', 'default'] device index defined above code known index having list available microphone names system. instance, above-given output, microphone having name "front" positioned index list. This done using method given below. sr.Microphone(device_index=3) above code just example, hence recommended interpreter. most projects, should default system microphone. Capturing microphone input using listen() Another method that will learn here listen method used capture input from microphone. Since have already created microphone instance, right time capture some input. Like most AudioFile class, microphone also treated context manager. captures input through Recognizer class having block inside accepting first argument then recording input from source until moment where microphone detects silence. frame this out, let's applied using given code. with source: audio r.listen(source) Once above code executed with block, should speaking something into microphone wait some time. interpreter might prompt display after some time. Once ">>>" returned prompt, assured that Recognizer recognize whatever say. Recognizer fails return prompt, there might some ambient noise picking stop that pressing Ctrl+C prompt back. adjust Noise prevailing your speech, need same method adjust_for_ambient_noise() Recognizer class. Since microphone input unpredictable compared audio file, always good idea always these while listening microphone input. precise noise-free output, with listen() method shown. with source: r.adjust_for_ambient_noise(source) audio r.listen(source) When above code, wait seconds that adjust_for_ambient Noise method does tasks. After code compiled run, speaking something into microphone wait interpreter recognize speech. recognizes returns prompt, working fine. also duration keyword again getting particular frame speech want recognized. Meanwhile, SpeechRecognizer documentation recommends using duration keyword duration keyword duration less. might also find that duration keyword used some cases, hence used default value generating better results. Also, notably possible that minimum value dependent input microphone's environment. Hence, duration second preferably considered best this kind task. Unrecognizable Speech With thebcodebase, have created some tangible code interpreter using microphone some unintelligible noises. bound that receive error like this. Traceback (most recent call last): File "<stdin>", line <module> File "/home/david/real_python/speech_recognition_primer/venv/lib/pyth on3.5/site-packages/speech_recognition/__init__.py", line 858, recognize_google isinstance(actual_result, dict) len(actual_result.get("alternative", [])) raise UnknownValueError() speech_recognition.UnknownValueError This error because unrecognized nature speech captured through microphone input, hence codebase advanced enough transcribe these short grunt noises vocal sounds. There might also case that interpreter prompt recognizing current input displaying something even close what captured through microphone. Hence, activities like clapping, clicks, other bars might raise exception correct output, respectively. Summary this long tutorial about speech recognition Python, learned schedule works from scratch. covered from conceptual knowledge hands-on experience creating real-time simple python speech recognizer that hear your speech display textual format console. also learned some critical methods deal with issue that commonly occurred while using SpeechRecognizer package learned rectify these issues. Python being widely-used programming scripting language covers most speech recognition applications because ambient libraries frameworks that display ability handle critical problems with just lines easy readable codes. Next TopicYield Return Python prev next