next prev Scraping Using Python What Scraping? Scraping technique extract large amount data from several websites. term "scraping" refers obtaining information from another source (webpages) saving into local file. example: Suppose working project called "Phone comparing website," where require price mobile phones, ratings, model names make comparisons between different mobile phones. collect these details checking various sites, will take much time. that case, scrapping plays important role where writing lines code desired results. Scrapping extracts data from websites unstructured format. helps collect these unstructured data convert structured form. Startups prefer scrapping because cheap effective large amount data without partnership with data selling company. Scrapping legal? Here question arises whether scrapping legal not. answer that some sites allow when used legally. scraping just tool right wrong way. scrapping illegal someone tries scrap nonpublic data. Nonpublic data reachable everyone; extract such data then violation legal term. There several tools available scrap data from websites, such Scrapping-bot Scrapper Octoparse Import.io Webhose.io Dexi.io Outwit Diffbot Content Grabber Mozenda Scrapper Chrome Extension Scrapping? have discussed above, scrapping used extract data from websites. should know that data. That data used various fields. Let's have look usage scrapping: Dynamic Price Monitoring widely used collect data from several online shopping sites compare prices products make profitable pricing decisions. Price monitoring using scrapped data gives ability companies know market condition facilitate dynamic pricing. ensures companies they always outrank others. Market Research eb Scrapping perfectly appropriate market trend analysis. gaining insights into particular market. large organization requires great deal data, scrapping provides data with guaranteed level reliability accuracy. Email Gathering Many companies personals e-mail data email marketing. They target specific audience their marketing. News Content Monitoring single news cycle create outstanding effect genuine threat your business. your company depends news analysis organization, frequently appears news. scraping provides ultimate solution monitoring parsing most critical stories. News articles social media platform directly influence stock market. Social Media Scrapping Scrapping plays essential role extracting data from social media websites such Twitter, Facebook, Instagram, find trending topics. Research Development large data such general information, statistics, temperature scrapped from websites, which analyzed used carry surveys research development. Python Scrapping? There other popular programming languages, choose Python over other programming languages scraping? Below describing list Python's features that make most useful programming language scrapping. Dynamically Typed Python, don't need define data types variables; directly variable wherever requires. saves time makes task faster. Python defines classes identify data type variable. Vast collection libraries Python comes with extensive range libraries such NumPy, Matplotlib, Pandas, Scipy, etc., that provide flexibility work with various purposes. suited almost every emerging field also scrapping extracting data manipulation. Less Code purpose scrapping save time. what spend more time writing code? That's Python, perform task lines code. Open-Source Community Python open-source, which means freely available everyone. biggest communities across world where seek help stuck anywhere Python code. basics scraping scrapping consists parts: crawler scraper. simple words, crawler horse, scrapper chariot. crawler leads scrapper extracts requested data. Let's understand about these components scrapping: crawler crawler generally called "spider." artificial intelligence technology that browses internet index searches content given links. searches relevant information asked programmer. scrapper scraper dedicated tool that designed extract data from several websites quickly effectively. scrappers vary widely design complexity, depending projects. does Scrapping work? These following steps perform scraping. Let's understand working scraping. Step Find that want scrape First, should understand requirement data according your project. webpage website contains large amount information. That's scrap only relevant information. simple words, developer should familiar with data requirement. Step Inspecting Page data extracted HTML format, which must carefully parsed reduce noise from data. some cases, data simple name address complex high dimensional weather stock market data. Step Write code Write code extract information, provide relevant information, code. Step Store data file Store that information required csv, xml, JSON file format. Getting Started with Scrapping Python vast collection libraries also provides very useful library scrapping. Let's understand required library Python. Library used scrapping Selenium- Selenium open-source automated testing library. used check browser activities. install this library, type following command your terminal. install selenium Note good PyCharm IDE. Pandas Pandas library used data manipulation analysis. used extract data store desired format. BeautifulSoup BeautifulSoup Python library that used pull data HTML files. mainly designed scrapping. works with parser provide natural navigating, searching, modifying parse tree. latest version BeautifulSoup 4.8.1. Let's understand BeautifulSoup library detail. Installation BeautifulSoup install BeautifulSoup typing following command: install Installing parser BeautifulSoup supports HTML parser several third-party Python parsers. install them according your dependency. list BeautifulSoup's parsers following: Parser Typical usage Python's html.parser BeautifulSoup(markup,"html.parser") lxml's HTML parser BeautifulSoup(markup,"lxml") lxml's parser BeautifulSoup(markup,"lxml-xml") Html5lib BeautifulSoup(markup,"html5lib") recommend install html5lib parser because much suitable newer version Python, install lxml parser. Type following command your terminal: install html5lib BeautifulSoup used transform complex HTML document into complex tree Python objects. there essential types object which mostly used: object corresponds HTML original document. soup bs4.BeautifulSoup("<b class "boldest">Extremely bold</b>) soup.b type(tag) Output: <class "bs4.element.Tag"> contains attributes methods, most important features name attribute. Name Every name, accessible .name: tag.name Attributes have number attributes. <b "boldest"> attribute "id" whose value "boldest". access tag's attributes treating dictionary. tag[id] add, remove, modify tag's attributes. done using dictionary. element tag['id'] 'verybold' tag['another-attribute'] delete tag['id']	 Multi-valued Attributes HTML5, there some attributes that have multiple values. class (consists more than css) most common multivalued attributes. Other attributes rel, rev, accept-charset, headers, accesskey. class_is_multi= 'class'} xml_soup BeautifulSoup('<p class="body strikeout"></p>', 'xml', multi_valued_attributes=class_is_multi) xml_soup.p['class'] [u'body', u'strikeout'] NavigableString string BeautifulSoup refers text within tag. BeautifulSoup uses NavigableString class contain these bits text. tag.string u'Extremely bold' type(tag.string) <class 'bs4.element.NavigableString'> string immutable means can't edited. replaced with another string using replace_with(). tag.string.replace_with("No longer bold") some cases, want NavigableString outside BeautifulSoup, unicode() helps turn into normal Python Unicode string. BeautifulSoup object BeautifulSoup object represents complete parsed document whole. many cases, object. means supports most methods described navigating tree searching tree. doc=BeautifulSoup("<document><content/>INSERT FOOTER HERE</document","xml") footer=BeautifulSoup("<footer>Here's footer</footer>","xml") doc.find(text="INSERT FOOTER HERE").replace_with(footer) print(doc) Output: ?xml version="1.0" encoding="utf-8"?> <document><content/><footer>Here's footer</footer></document> Scrapping Example: Let's take example understand scrapping practically extracting data from webpage inspecting whole page. First, open your favorite page Wikipedia inspect whole page, before extracting data from webpage, should ensure your requirement. Consider following code: #importing BeautifulSoup Library importbs4 import requests #Creating requests requests.get("https://en.wikipedia.org/wiki/Machine_learning") print("The object type:",type(res)) Convert request object Beautiful Soup Object soup bs4.BeautifulSoup(res.text,'html5lib') print("The object type:",type(soup) Output: object type <class 'requests.models.Response'> Convert object into: <class 'bs4.BeautifulSoup'> following lines code, extracting headings webpage class name. Here front-end knowledge plays essential role inspecting webpage. soup.select('.mw-headline') soup.select('.mw-headline'): print(i.text,end ',') Output: Overview,Machine learning tasks,History relationships other fields,Relation data mining,Relation optimization,Relation statistics, Theory,Approaches,Types learning algorithms,Supervised learning,Unsupervised learning,Reinforcement learning,Self-learning,Feature learning,Sparse dictionary learning,Anomaly detection,Association rules,Models,Artificial neural networks,Decision trees,Support vector machines,Regression analysis,Bayesian networks,Genetic algorithms,Training models,Federated learning,Applications,Limitations,Bias,Model assessments,Ethics,Software,Free open-source software,Proprietary software with free open-source editions,Proprietary software,Journals,Conferences,See also,References,Further reading,External links, above code, imported requested library. third line, created object send request webpage. observe that have extracted heading from webpage. Webpage Wikipedia Learning Let's understand another example; will make request create parse Tree object (soup) with BeautifulSoup Python built-in "html5lib" parser. Here will scrap webpage given link (https://www.javatpoint.com/). Consider following code: following code: importing libraries from import BeautifulSoup import requests url="https://www.javatpoint.com/" Make request fetch HTML content html_content requests.get(url).text Parse html content soup BeautifulSoup(html_content, "html5lib") print(soup.prettify()) print parsed data html above code will display html code javatpoint homepage. Using BeautifulSoup object, i.e. soup, collect required data table. Let's print some interesting information using soup object: Let's print title page. print(soup.title) Output: will give output follow: <title>Tutorials List Javatpoint</title> above output, HTML included with title. want text without tag, following code: print(soup.title.text) Output: will give output follow: Tutorials List Javatpoint entire link page along with attributes, such href, title, inner Text. Consider following code: link soup.find_all("a"): print("Inner Text {}".format(link.text)) print("Title {}".format(link.get("title"))) print("href {}".format(link.get("href"))) Output: will print links along with attributes. Here display them: href https://www.facebook.com/javatpoint Inner Text title None href https://twitter.com/pagejavatpoint Inner Text title None href https://www.youtube.com/channel/UCUnYvQVCrJoFWZhKK3O2xLg Inner Text title None href https://javatpoint.blogspot.com Inner Text Learn Java Title None href https://www.javatpoint.com/java-tutorial Inner Text Learn Data Structures Title None href https://www.javatpoint.com/data-structure-tutorial Inner Text Learn Programming Title None href https://www.javatpoint.com/c-programming-language-tutorial Inner Text Learn Tutorial Demo: Scraping Data from Flipkart Website this example, will scrap mobile phone prices, ratings, model name from Flipkart, which popular e-commerce websites. Following prerequisites accomplish this task: Prerequisites: Python Python with Selenium, BeautifulSoup, Pandas libraries installed. Google chrome browser Scrapping Parser such html.parser, xlml, etc. Step Find desired scrap initial step find that want scrap. Here extracting mobile phone details from flipkart. this page https://www.flipkart.com/search?q=iphones&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off. Step Inspecting page necessary inspect page carefully because data usually contained within tags. need inspect select desired tag. inspect page, right-click element click "inspect". Step Find data extracting Extract Price, Name, Rating, which contained "div" tag, respectively. Step Write Code from import BeautifulSoupas soup from urllib.request import urlopen uReq Request from webpage myurl "https://www.flipkart.com/search?q=iphones&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off" uClient uReq(myurl) page_html uClient.read() uClient.close() page_soup soup(page_html, features="html.parser") print(soup.prettify(containers[0])) This variable held html webpage containers page_soup.find_all("div",{"class": "_3O0U0u"}) container containers[0] print(soup.prettify(container)) price container.find_all("div",{"class": "col col-5-12 _2o7WAb"}) print(price[0].text) ratings container.find_all("div",{"class": "niH0FQ"}) print(ratings[0].text) print(len(containers)) print(container.div.img["alt"]) Creating File that will store data filename "product1.csv" open(filename,"w") headers "Product_Name,Pricing,Ratings\n" f.write(headers) container containers: product_name container.div.img["alt"] price_container container.find_all("div", {"class": "col col-5-12 _2o7WAb"}) price price_container[0].text.strip() rating_container container.find_all("div",{"class":"niH0FQ"}) ratings rating_container[0].text print("product_name:"+product_name) print("price:"+price) print("ratings:"+ str(ratings)) edit_price ''.join(price.split(',')) sym_rupee edit_price.split("?") add_rs_price "Rs"+sym_rupee[1] split_price add_rs_price.split("E") final_price split_price[0] split_rating str(ratings).split(" final_rating split_rating[0] print(product_name.replace(",", "|")+","+final_price+","+final_rating+"\n") f.write(product_name.replace(",", "|")+","+final_price+","+final_rating+"\n") f.close() Output: scrapped details iPhone saved those details file output. above code, comment lines code testing purpose. remove those comments observe output. this tutorial, have discussed basic concepts scrapping described sample scrapping from leading online ecommerce site flipkart. Next TopicPython JSON prev next