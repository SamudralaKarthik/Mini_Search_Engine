next prev Music Recommendation System Python Project with Source Code Python this project? Over years, Python earned superstar status data science. data fans adore offers simple introduction statistical science machine learning. There several built-in libraries challenging data science projects, which simple create. Python's popularity also straightforward code readability. When compared other complex languages, syntax skeletal minimal. list libraries available usage Python data science incomplete, includes seaborn, Matlab, sci-kit learn, SciPy, pandas, requests, regex, NumPy, etc. python good option beginners start learning data science, rightly utilize audio streaming services, including Gaana, Jio Saavn, Spotify, iTunes. ponder these platforms propose songs based your preferences when listening music them? These services machine learning algorithms. This that they give songs they believe you'll like. We'll discuss these models this article them create music recommendation engine. assist beginning your educational path gaining practical experience required data science career, here selection vetted Python data science projects. It's time play around with Data Science Projects experiment with different strategies solving business problem gain data-driven insights. offering visual straightforward methods organize clean your data, software like Tableau Prep assist fostering great data culture. Tableau Prep features products: Mondrian Prep Director scheduling, managing, monitoring flows throughout your company Tableau Prep Builder creating data flows. data cleaning tool analysts administrators begin their studies more quickly with greater confidence data, saving administrator time. Making successful efficient business decisions requires understanding data quality tools taken construct, manage, transform data. This vital procedure will help your firm further establish data culture. learn design firm Tinuiti grew their advanced analytics 500+ clients centralized 100plus data sets Tableau Prep reading about they Music Recommendation System KKBox Dataset Today's world surrounded music. 2021, more than million songs will available Spotify alone, proving accessible music Other services include KKBox, Gaana, Saavn, Apple Music. fresh content become found field with much content currently available? Recommendations system users discover songs develop musical likes. Recommendation algorithms profitable music streaming businesses well. They benefit from increased engagement audience growth their platform. Asia, largest streaming services KKBox. Dataset Description information includes music user metadata. User- song-specific information, such user ID'S, user Registration date, song ID'S, song genre, song ArtistName, song release date, included metadata. information includes when user plays piece music only once. each song-user combination, this information particular. dataset consists three files: This file contains information user-song pairs, including user IDs, source system tab, source type, source screentime, target. target indicates user tuned same music within month. includes information about song IDs, song genre, song artist, song lyricist, etc. Target indicates that user played song within days; Target signifies that user play song. individ'suals .csv contains client account information like user_name, user_age, user_gender, user_subscription_plan, forth. Remove duplicate pointless observations well undesirable observations from your dataset. majority duplicate observations will occur during data gathering. Duplicate data produced when merge data sets from several sources, scrape data, from clients other departments. most important factors consider this procedure de-duplication. Those observations deemed irrelevant when observe data that pertain particular issue attempting study. instance, might eliminate those useless observations wish examine data about millennial clients, your dataset also includes observations from earlier generations. addition providing more understandable effective dataset, this increase analysis efficiency reduce divergence from your main aim. Step Data Cleaning Anomalies, outliers, missing values present dataset. These situations affect accurately efficiently algorithms implemented. dataset contains 30-50% outliers missing values. data needs uniformly normalized throughout. Data cleansing removing information from your dataset that does belong there. methods used sanitize that data main topic this essay. process changing data from place architecture another known data transformation. Transformation activities also known data wrangling data munging when translating data from "hard" data form into another format archiving analysis. employ following methods clean data: Outlier Recognition Treatment. Outliers ludicrous values outside acceptable range label. instance, user's below zero above hundred deemed ludicrous. might stricter specific circumstances, such when buying alcohol between 100. Benefits data cleaning When have clean data, make decisions using highest-quality information eventually boost productivity. Benefits comprise: Removal inaccuracies when several data sources involved. Clients happier, employees less annoyed when there fewer mistakes. capacity your data's many functions planned uses. Monitoring mistakes improving reporting make resolving incorrect damaged data easier future operations allowing users identify where issues coming from. Step Addition Missing Values Imputing entails substituting different value lacking values dataset. divide user-song pairings into distinct categories: repetitions non-repeats. Replacing empty values dataset with proper data median average values used fill gaps left missing values. Eliminating null values this situation, pieces information with missing data eliminated, which causes data loss. Following this process, dataset file's size decreases. Creating Missing label Data points with missing values placed section labeled "missing." categorizes lacking resources into single group. Finally, change numerical counterparts string labels. Step Correct structural issues When test exchange data find naming practices, typos, wrong capitalization, such structural faults. Mislabeled sections classes result from these inconsistencies. instance, might both "N/A" "Not Applicable," they must assessed belonging same category. Step Eliminate unwelcome outliers There will frequently isolated findings that, first look, seem need data evaluating. Removing outlier have good reason such incorrect data entry, will enhance accuracy data currently working with. However, occasionally outlier's appearance will support theory you're working Remember that outlier doesn't necessarily indicate that something needs fixed. determine reliability number, this step necessary. outlier turns incorrect unimportant analysis, should remove Step Data standardization Data standardization allows recognize transform data from many formats into standardized one. Data standardization useful don't have data restrictions data entry company data have conflicting forms. contrast data validation, standardization procedures used data that already been gathered. This entails creating scripts transform your soiled data into reliable ones. Matching strings: rigorous fuzzy string-matching techniques find exact close matches with your data legitimate values standardize inconsistent data. comparing your data characters expected valid values, eliminate modify strings that don't match. Libraries NumPy, Sklearn, Pandas develop music recommendation system, following modelling strategies will assessed this project: Regression with logit algorithms, regression most straightforward. found Sklearn package Python little more than linear model. Determination Tree decision tree uses tree structure arrive decisions outcomes. Each level offers option choosing branches. result output tree after each iteration. Forest Random Decision Trees gathered into Random Forest. Recommended models I've already mentioned, these music streaming sites models offer songs enjoy. These models referred classes Recommendation Python package. must import Pandas Numpy libraries into this package: import numpy import pandas Let's talk about models that applied recommendations: Recommendation Popularity: This algorithm suggests music that trending popular your area. This model based songs well-liked your area constantly played system users. source code popularity recommendation class popularity_recommender(): __init__(s): s.t_data None s.u_id's None #ID'S users s.i_id's None #ID'S Song users listening s.pop_recommendations None #getting recommendations according popularity #Creating system models create_p(s, t_data, u_id's, i_id's): s.t_data t_data s.u_id's u_id's s.i_id's i_id's recommendation score based number times each music been listened t_data_grouped t_data.groupby([s.i_id's]).agg({s.u_id's: 'count'}).reset_index() t_data_grouped.rename(columns {'user_id's': 'score'},inpnlace=True) #Sort songs user ratings. t_data_sort t_data_grouped.sort_values(['score', s.i_id's], ascending [0,1]) #Create ranking recommendations based score t_data_sort['Rank'] t_data_sort['score'].rank(ascending=0, method='first') recommendations here s.pop_recommendations t_data_sort.head(10) #To give recommendations using system model fits(dfs, algo, flag=0): flag: algo.fits(df) else: algo.partial_fit(df) dfs['label'] algo.labels_ return (dfs, algo) predict(t, y_preds t[1].predict(Y) modes pd.Series(y_preds).mode() return t[0][t[0]['label'] mode.loc[0]] recommend(recommendations, meta, dats Y['track_id']: dats.append(i) genre_modes meta.loc[dat]['genres'].mode() artist_modes meta.loc[dat]['artist_name'].mode() return metas[meta['genre'] genre_mode.iloc[0]], meta[meta['artist_name'] artist_modes.iloc[0]], meta.loc[recommendations['track_id']] fit(X, kmeans, recommendations predict(t, output recommend(recommendations, recommend_p(s, u_id's): u1_recommendations s.pop_recommendations column user where music recommendations generated. u1_recommendations['user_id's'] u_id's #Bringing user_id's column upper front cols u1_recommendations.columns.tolist() cols cols[-1:] cols[:-1] u1_recommendations u1_recommendations[cols] return u1_recommendations Similarity Recommendation: Your daily music listening habits taken into account this model. instance: Let's Spotify listen Linkin Park's song Numb. After watching songs, given music recommendations such Boulevard Shattered Dreams Green Linkin Park because these songs have same artist genre. Source code: #python Class Items similar nature, Recommender System model class similarity_recommender1(): __init__(s): s.t_data None s.u_id's None s.i_id's None s.co_matrix None s.songs_dic None s.rev_songs_dic None s.i_similarity_recommendations11 None get_u_items(s, u_data s.t_data[s.t_data[s.u_id's] u] u_items list(u_data[s.i_id's].unique()) return u_items get_i_users(s, i_data11 s.t_data[s.t_data[s.i_id's] i] i_users set(i_data[s.u_id's].unique()) return i_users #Get unique songs training data get_all_items1_t_data(s): all_items1 list(s.t_data[s.i_id's].unique()) return all_items1 #Construct co-occurrence matrix construct_co_matrix(s, u_songs, a_songs): #Get users songs user_songs11. u_songs_users range(0, len(u_songs)): u_songs_users.append(s.get_i_users(u_songs[i])) #Initializing item co-occurence matrix size len(user_songs11) len(songs) co_matrix npn.matrix(npn.zeros(shape=(len(u_songs), len(a_songs))), float) Determine comparable songs user been listening other songs training set. range(0,len(a_songs)): #Calculating unique listeners songs. songs_i_data11 s.t_data[s.t_data[s.i_id's] a_songs[i]] users_i set(songs_i_data[s.u_id's].unique()) range(0,len(u_songs)): #Getting unique users means listeners songs (item) users_j u_songs_users[j] Calculate songs common listened listeners users_intersection11 users_i.intersection(users_j) #Calculate co-occurence_matrix[i,j] Jaccard Index len(users_intersection) #Calculate songs listened users_union users_i.union(users_j) co_matrix[j,i] float(len(users_intersection))/float(len(users_union)) else: co_matrix[j,i] return co_matrix #Use co-occurrence matrix make recommendations generate_top_r(s, user, co-occurence_matrix, a_songs, u_songs): print("Non zero values co-occurence_matrix :%d" npn.count_nonzero(co-occurence_matrix)) #Calculate average scores co-occurrence matrix songs listened user. user_sim_scores1 co-occurence_matrix.sum(axis=0)/float(co-occurence_matrix.shape[0]) user_sim_scores1 npn.array(user_sim_scores)[0].tolist() #Sort indices user_sim_scores1 based their value also maintain corresponding score s_index sorted(((e,i) i,e enumerate(list(user_sim_scores))), reverse=True) #Create dataframe from following columns ['user_id's', 'songs', 'score', 'rank'] #index npn.arange(1) array numbers number samples pandas.DataFrame(columns=columns) #Filling dataframe with songs rank range(0,len(s_index)): ~npn.isnan(s_index[i][0]) a_songs[s_index[i][1]] u_songs rank df1.loc[len(df1)]=[user,a_songs[s_index[i][1]],s_index[i][0],rank] rank rank+1 #Handling case where recommendation df1.shape[0] print("There songs available current user's similarity-based recommendation algorithm.") return else: return #Create system model create_s(s, t_data, u_id's, i_id's): s.t_data t_data s.u_id's u_id's s.i_id's i_id's #Use model make recommendations recommend_s(s, #A. Getting unique songs this user u_songs s.getting_u_items(u) print("No. songs user: len(u_songs)) Getting songs data a_songs1 s.getting_all_items1_t_data() print("No. songs list: len(a_songs)) Make co-occurrence matrix size len(user_songs11) len(songs) co_matrix s.construct_co_matrix(u_songs, a_songs) df_r s.generate_top_r(u, co_matrix, a_songs, u_songs) return similar_items(s, i_list): u_songs i_list a_songs1 s.getting_all_items1_t_data() print("no. unique songs set: len(a_songs)) Make co-occurrence matrices size len(user_songs11) len(songs) co_matrix s.construct_co_matrix(u_songs, a_songs) matrix make recommendations df_r s.generate_top_r(u, co_matrix, a_songs, u_songs) return df_r integrate them into file using Python libraries necessary this task Guid'seline package: Source code: import pandas from sklearn.model_selection import train_test_split import numpy import time import Recommenders Recommenders After that, we'll open a.csv file with data obtain number occasions user listened each song line five. Source code: #Read user_id's, songs_id's, listen_count process downloading data from outside sources could take some time. triplets 'https://static.turi.com/datasets/millionsongs/10000.txt' songs_metadata 'https://static.turi.com/datasets/millionsongs/songs_data.csv' songs_df_a pandas.read_table(triplets,header=None) songs_df_a.columns ['user_id's', 'songs_id's', 'listen_count'] #Read songs metadata songs_df_b pandas.read_csv(songs_metadata) Combine columns song titles artists create column. songs_df1 pandas.merge(songs_df_a, songs_df_b.drop_duplicates(['songs_id's']), on="songs_id's", how="left") songs_df1.head() Output: better understanding, will display number songs, number rows, dataset file. Source code: print("Total songs:",len(songs_df1)) Output: Total songs: 2000000 Next, we'll build dataframe from portion provided dataset. Source code: songs_df1 songs_df1.head(10000) Combine columns song titles artists create column. songs_df1['songs'] songs_df1['title'].map(str) songs_df1['artist_name'] column listen_count denotes times songs have been listened Using this column, we'll find dataframe consisting popular songs: songs_gr songs_df1.groupby(['songs']).agg({'listen_count': 'count'}).reset_index() grouped_sum songs_gr['listen_count'].sum() songs_gr['percentage'] songs_gr['listen_count'].div(grouped_sum)*100 songs_gr.sort_values(['listen_count', 'songs'], ascending [0,1]) Because output long enough display full, I've excerpted below. Output: Anyway Armand Helden A-TRAK Present 5139 high fives Four Tets 5142 white rooms Booka Shades 5132 paranoid's androids Christophers O'Riley 5192 ¿LoVes? [Piano ¿LoVes? [Piano Voz] Alehjandro Sanz 51502 Época Gotan Project rows columns 518 Your Love Outfield 7121 Your Mouth Telefon Tel Aviv Rook Naar Rozen Nijs 7131 Zebra Beach Houses 7132 Zebra Mans 71332 Zero Pain Machinery 71352 Zopf: pigtail Penguin Café Orchestra 7137s2 5123 Your Songs (Alternate Take Cilla Black2 7126 Your Visits Getting Shorter Bloc Party2 7127 Your Woman White Towns 7130 Rook Naar Rozen Nijs 7131 Zebra Beach Houses 7132 Zebra Mans 7133 Zero Pain Machinery 7132 Zopf: pigtail Penguin Café Orchestra 5137s2 Anyway Armand Helden A-TRAK Present 51392 high fives Four Tets 51402 white rooms Booka Shades 51432 paranoid's androids Christophers O'Riley 51492 LoVes [Piano ¿LoVes? [Piano Voz] Alehjandro Sanz 51502 Época Gotan Project 51512 rows columns Next TopicPython counter prev next