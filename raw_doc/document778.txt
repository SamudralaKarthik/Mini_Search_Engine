



next →
← prev

Decision Tree in Python Sklearn
Using a machine learning algorithm called a decision tree, we can represent the choices and the potential consequences of those decisions, covering outputs, input costs, and utilities.
The supervised learning methods group includes the decision-making algorithm. It works with output parameters that are categorized and continuous.
Decision Tree Algorithm
In a decision tree, which resembles a flowchart, an inner node represents a variable (or a feature) of the dataset, a tree branch indicates a decision rule, and every leaf node indicates the outcome of the specific decision. The first node from the top of a decision tree diagram is the root node. We can split up data based on the attribute values that correspond to the independent characteristics.
The recursive partitioning method is for the division of a tree into distinct elements. Making decisions is aided by this decision tree's comprehensive structure, which looks like a flowchart. It offers a diagrammatic model that exactly mirrors how individuals reason and choose. Because of this property of the flowchart, decision trees are easy to understand and comprehend.
The Decision Tree Algorithm: How Does It Operate?
Every decision tree algorithm's fundamental principle is as follows:

To divide the data based on target variables, choose the best feature employing Attribute Selection Measures (ASM).
Then it will divide the dataset into smaller sub-datasets and designate that feature as a decision node for that branch.
Once one of the conditions matches, the procedure is repeated recursively for every child node to begin creating the tree.
The identical property value applies to each of the tuples.

There aren't any more qualities left.
There aren't any more occurrences.


Decision Tree Regression
To predict future events using the decision tree algorithm and generate an insightful output of continuous data type, the decision tree regression algorithm analyses an object's attributes and trains this machine learning model as a tree. Since a predetermined set of discrete numbers does not entirely define it, the output or outcome is not discrete.
This model illustrates a discrete output in the cricket match prediction that predicts whether a certain team will win or lose a match.
A sales forecasting machine learning model that forecasts a firm's profit ranges will increase throughout a fiscal year depending on the company's preliminary figures illustrates continuous output.
A decision tree regression algorithm is utilized in this instance to forecast continuous values.
After talking about sklearn decision trees, let's look at how they are implemented step-by-step.
Code

# Python program to implement decision tree algorithm and plot the tree

# Importing the required libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn import metrics
import seaborn as sns
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn import tree

# Loading the dataset
iris = load_iris()

#converting the data to a pandas dataframe
data = pd.DataFrame(data = iris.data, columns = iris.feature_names)

#creating a separate column for the target variable of iris dataset 
data['Species'] = iris.target

#replacing the categories of target variable with the actual names of the species
target = np.unique(iris.target)
target_n = np.unique(iris.target_names)
target_dict = dict(zip(target, target_n))
data['Species'] = data['Species'].replace(target_dict)

# Separating the independent dependent variables of the dataset
x = data.drop(columns = "Species")
y = data["Species"]
names_features = x.columns
target_labels = y.unique()

# Splitting the dataset into training and testing datasets
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 93)

# Importing the Decision Tree classifier class from sklearn
from sklearn.tree import DecisionTreeClassifier

# Creating an instance of the classifier class
dtc = DecisionTreeClassifier(max_depth = 3, random_state = 93)

# Fitting the training dataset to the model
dtc.fit(x_train, y_train)

# Plotting the Decision Tree
plt.figure(figsize = (30, 10), facecolor = 'b')
Tree = tree.plot_tree(dtc, feature_names = names_features, class_names = target_labels, rounded = True, filled = True, fontsize = 14)
plt.show()
y_pred = dtc.predict(x_test)

# Finding the confusion matrix
confusion_matrix = metrics.confusion_matrix(y_test, y_pred)
matrix = pd.DataFrame(confusion_matrix)
axis = plt.axes()
sns.set(font_scale = 1.3)
plt.figure(figsize = (10,7))

# Plotting heatmap
sns.heatmap(matrix, annot = True, fmt = "g", ax = axis, cmap = "magma")
axis.set_title('Confusion Matrix')
axis.set_xlabel("Predicted Values", fontsize = 10)
axis.set_xticklabels([''] + target_labels)
axis.set_ylabel( "True Labels", fontsize = 10)
axis.set_yticklabels(list(target_labels), rotation = 0)
plt.show()

Output:





Next TopicPython Books for Data Structures and Algorithms




← prev
next →




