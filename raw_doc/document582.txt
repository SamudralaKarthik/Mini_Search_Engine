



next →
← prev

Learning Vector Quantization
Learn Vector Quantization (or LVQ) is a type of Artificial Neural Network that is also influenced by the biological model that represents neural networks. It is based on a prototype algorithm for supervised learning and classification. It has developed its network using an algorithm of competitive learning similar to the Self Organizing Map. It is also able to deal with the problem of multiclass classification. LVQ is composed of two layers, one of which is the input layer, and the second is called the Output. The structure of Learning Vector Quantization with the number of classes that are in the input data and the numbers of features that are input for every sample can be found below:

How Learning Vector Quantization works?
Let's suppose that we have input data of size (m and the number) with m being the training samples, while n refers to the number of components in each instance and an arbitrary label vector of the size (1 m). Then, it is initialized with its weights in size (n and C) from the initial number of training samples that have different labels. They must be removed in all samples of training. In this case, c is an indication of the classes. Then, iterate over the remaining input information for each example of training that it changes to the winner vector (weight vector) with the closest distance (e.g., Euclidean distance ) from the example of training ).
The weight updation rules are provided by:

if correctly_classified:
wij(new) = wij(old) + alpha(t) * (xik - wij(old))
else:
wij(new) = wij(old) - alpha(t) * (xik - wij(old))

Where alpha represents a learning rate over time t, J is an award-winning vector. In addition, i is the characteristic of the training example, and k represents the number k of the training sample using an input dataset. After training on the LVQ network, weights trained are used to classify new examples. The new instance is labelled by an LVQ class that is the one winning.
Algorithm
The steps involved include:

Weight initialization
From 1 to N of Epochs
Select a good training example
Find the winning vector
Make sure you update the vector that is winning
Repeat steps 3, 4, and 5 for every exercise example.
Classify test samples

Below is the implementation.
Code:

import math as M
  
  
class LVQ :
      
    # Here, we will create the function which computes the winning vector
    # by Euclidean distance
    def winner1( self, weights, sample ) :
          
        D_0 = 0
        D_1 = 0
          
        for K  in range( len( sample ) ) :
            D_0 = D_0 + M.pow( ( sample[K] - weights[0][K] ), 2 )
            D_1 = D_1 + M.pow( ( sample[K] - weights[1][K] ), 2 )
              
            if D_0 > D_1 :
                return 0
            else : 
                return 1
  
    # Here, we will create the function which here updates the winning vector     
    def update1( self, weights, sample, J, alpha1 ) :
        for k in range(len(weights)) :
            weights[J][k] = weights[J][k] + alpha1 * ( sample[k] - weights[J][k] ) 
  
# Driver code
def main() :
  
    # Here, we are training Samples ( g, h ) with their class vector
    P =  [[ 0, 0, 1, 1 ],  [ 1, 0, 1, 0 ], 
          [ 0, 0, 0, 1 ], [ 0, 1, 1, 0 ],
          [ 1, 1, 1, 0 ], [ 1, 0, 1, 1 ],] 
  
    Q = [ 0, 1, 0, 1, 0, 1 ]
    g, h = len( P ), len( P[0] )
      
    # HEre, we will initialize the weight ( h, c )
    weights = []
    weights.append( P.pop( 0 ) )
    weights.append( P.pop( 1 ) )
  
    # Samples used in weight initialization will
    # not use in training
    g = g - 2
      
    # training
    ob1 = LVQ()
    epochs1 = 3
    alpha1 = 0.1
      
    for k in range( epochs1 ) :
        for o in range( g ) :
              
            # Sample selection
            T = P[o]
              
            # Compute winner
            J = ob1.winner1( weights, T )
          
            # Update weights
            ob1.update1( weights, T, J, alpha1 )
              
    # classify new input sample
    T = [ 0, 1, 1, 0 ]
    J = ob1.winner1( weights, T )
    print( "Sample T belongs to class : ", J )
    print( "Trained weights : ", weights )
      
if __name__ == "__main__":
    main()

Output:
Sample T belongs to class :  0
Trained weights :  [[0.3660931, 0.2816541, 1, 1], [0.33661, 0.1729, 0, 1]]



Next TopicLemmatization and Tokenize with TextBlob




← prev
next →




