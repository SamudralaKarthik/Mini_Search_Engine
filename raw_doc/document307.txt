



next →
← prev

Best Python libraries for Machine Learning
Machine learning is a science of programming the computer by which they can learn from different types of data. According to machine learning's definition of Arthur Samuel - "Field of study that gives computers the ability to learn without being explicitly programmed". The concept of machine learning is basically used for solving different types of life problems.

In previous days, the users used to perform tasks of machine learning by manually coding all the algorithms and using mathematical and statistical formulas.
This process was time-consuming, inefficient, and tiresome compared to Python libraries, frameworks, and modules. But in today's world, users can use the Python language, which is the most popular and productive language for machine learning. Python has replaced many languages as it is a vast collection of libraries, and it makes work easier and simpler.
In this tutorial, we will discuss the best libraries of Python used for Machine Learning:

NumPy
SciPy
Scikit-learn
Theano
TensorFlow
Keras
PyTorch
Pandas
Matplotlib

NumPy

NumPy is the most popular library in Python. This library is used for processing large multi-dimensional array and matrix formation by using a large collection of high-level mathematical functions and formulas. It is mainly used for the computation of fundamental science in machine learning. It is widely used for linear algebra, Fourier transformation, and random number capabilities. There are other High-end libraries such as TensorFlow, which user NumPy as internal functioning for manipulation of tensors.
Example:

import numpy as nup
 
# Then, create two arrays of rank 2
K = nup.array([[2, 4], [6, 8]])
R = nup.array([[1, 3], [5, 7]])
 
# Then, create two arrays of rank 1
P = nup.array([10, 12])
S = nup.array([9, 11])
 
# Then, we will print the Inner product of vectors
print ("Inner product of vectors: ", nup.dot(P, S), "\n")
 
# Then, we will print the Matrix and Vector product
print ("Matrix and Vector product: ", nup.dot(K, P), "\n")
 
# Now, we will print the Matrix and matrix product
print ("Matrix and matrix product: ", nup.dot(K, R))

Output:
Inner product of vectors: 222 

Matrix and Vector product: [ 68 156] 

Matrix and matrix product: [[22 34]
                                                   [46 74]]

SciPy

SciPy is a popular library among Machine Learning developers as it contains numerous modules for performing optimization, linear algebra, integration, and statistics. SciPy library is different from SciPy stack, as SciPy library is one of the core packages which made up the SciPy stack. SciPy library is used for image manipulation tasks.
Example 1:

from scipy import signal as sg
import numpy as nup
K = nup.arange(45).reshape(9, 5)
domain_1 = nup.identity(3)
print (K, end = 'KK')
print (sg.order_filter (K, domain_1, 1))

Output:
r (K, domain_1, 1))
Output:
[[ 0  1  2  3  4]
 [ 5  6  7  8  9]
 [10 11 12 13 14]
 [15 16 17 18 19]
 [20 21 22 23 24]
 [25 26 27 28 29]
 [30 31 32 33 34]
 [35 36 37 38 39]
 [40 41 42 43 44]] KK [[ 0.  1.  2.  3.  0.]
 [ 5.  6.  7.  8.  3.]
 [10. 11. 12. 13.  8.]
 [15. 16. 17. 18. 13.]
 [20. 21. 22. 23. 18.]
 [25. 26. 27. 28. 23.]
 [30. 31. 32. 33. 28.]
 [35. 36. 37. 38. 33.]
 [ 0. 35. 36. 37. 38.]]

Example 2:

from scipy.signal import chirp as cp
from scipy.signal import spectrogram as sp
import matplotlib.pyplot as plot
import numpy as nup
t_T = nup.linspace(3, 10, 300)
w_W = cp(t_T, f0 = 4, f1 = 2, t1 = 5, method = 'linear')
plot.plot(t_T, w_W)
plot.title ("Linear Chirp")
plot.xlabel ('Time in Seconds)')
plot.show()

Output:

Scikit-learn

Scikit-learn is a Python library which is used for classical machine learning algorithms. It is built on the top of two basic libraries of Python, that is NumPy and SciPy. Scikit-learn is popular in Machine learning developers as it supports supervised and unsupervised learning algorithms. This library can also be used for data-analysis, and data-mining process.
Example:

from sklearn import datasets as ds
from sklearn import metrics as mt
from sklearn.tree import DecisionTreeClassifier as dtc
 
# load the iris datasets
dataset_1 = ds.load_iris()
 
# fit a CART model to the data
model_1 = dtc()
model_1.fit(dataset_1.data, dataset_1.target)
print(model)
 
# make predictions
expected_1 = dataset_1.target
predicted_1 = model_1.predict(dataset_1.data)
 
# summarize the fit of the model
print (mt.classification_report(expected_1, predicted_1))
print(mt.confusion_matrix(expected_1, predicted_1))

Output:
DecisionTreeClassifier()
              precision    recall f1-score   support

           0       1.00      1.00      1.00        50
           1       1.00      1.00      1.00        50
           2       1.00      1.00      1.00        50

    accuracy                           1.00       150
   macro avg       1.00      1.00      1.00       150
weighted avg       1.00      1.00      1.00       150

[[50  0  0]
 [ 0 50  0]
 [ 0  0 50]]

Theano

Theano is a famous library of Python, which is used for defining, evaluating, and optimizing mathematical expressions, which also efficiently involves multi-dimensional arrays.
It is achieved by optimizing the utilization of CPU and GPU. As machine learning is all about mathematics and statistics, Theano makes it easy for the users to perform mathematical operations.
It is extensively used for unit-testing and self-verification for detecting and diagnosing different types of errors. Theano is a powerful library that can be used on a large scale computationally intensive scientific project. It is a simple and approachable library, which an individual can use for their projects.
Example:

import theano as th
import theano.tensor as Tt
k = Tt.dmatrix('k')
r = 1 / (1 + Tt.exp(-k))
logistic_1 = th.function([k], r)
logistic_1([[0, 1], [-1, -2]])

Output:
array([[0.5, 0.71135838],
       [0.26594342, 0.11420192]])

TensorFlow

TensorFlow is an open-source library of Python which is used for high performance of numerical computation. It is a popular library, which was developed by the Brain team in Google. TensorFlow is a framework that involves defining and running computations involving tensors. TensorFlow can be used for training and running deep neural networks, which can be used for developing several Artificial Intelligence applications.
Example:

import tensorflow as tsf
 
# Initialize two constants
K_1 = tsf.constant([2, 4, 6, 8])
K_2 = tsf.constant([1, 3, 5, 7])
 
# Multiply
result = tsf.multiply(K_1, K_2)
 
# Initialize the Session
sess_1 = tsf.Session()
 
# Print the result
print (sess_1.run(result))
 
# Close the session
sess_1.close()

Output:
[ 2 12 30 56]

Keras

Keras is a high-level neural networking API, which is capable of running on top of TensorFlow, CNTK and Theano libraries. It is a very famous library of Python among Machine learning developers. It can run without a glitch on both CPU and GPU. IT makes it really easy and simple for Machine Learning beginners and for designing a Neural Network. It is also used for fast prototyping.
Example:

import numpy as nup
from tensorflow import keras as ks
from tensorflow.keras import layers as ls
number_classes = 10
input_shapes = (28, 28, 1)

# Here, we will import the data, and split it between train and test sets
(x_1_train, y_1_train), (x_2_test, y_2_test) = ks.datasets.mnist.load_data()

# now, we will Scale images to the [0, 1] range
x_1_train = x_1_train.astype("float32") / 255
x_2_test = x_2_test.astype("float32") / 255
# we have to make sure that the images have shape (28, 28, 1)
x_1_train = nup.expand_dims(x_1_train, -1)
x_2_test = nup.expand_dims(x_2_test, -1)
print ("x_train shape:", x_1_train.shape)
print (x_1_train.shape[0], "Training samples")
print (x_2_test.shape[0], "Testing samples")


# Then we will convert class vectors to binary class matrices
y_1_train = ks.utils.to_categorical(y_1_train, number_classes)
y_2_test = ks.utils.to_categorical(y_2_test, number_classes)
model_1 = ks.Sequential(
    [
        ks.Input(shape = input_shapes),
        ls.Conv2D(32, kernel_size = (3, 3), activation = "relu"),
        ls.MaxPooling2D(pool_size = (2, 2)),
        ls.Conv2D(64, kernel_size = (3, 3), activation = "relu"),
        ls.MaxPooling2D(pool_size = (2, 2)),
        ls.Flatten(),
        ls.Dropout(0.5),
        ls.Dense(number_classes, activation = "softmax"),
    ]
)

model_1.summary()

Output:
x_train shape: (60000, 28, 28, 1)
60000 Training samples
10000 Testing samples
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 26, 26, 32)        320       
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         
_________________________________________________________________
flatten (Flatten)            (None, 1600)              0         
_________________________________________________________________
dropout (Dropout)            (None, 1600)              0         
_________________________________________________________________
dense (Dense)                (None, 10)                16010     
=================================================================
Total params: 34,826
Trainable params: 34,826
Non-trainable params: 0
_________________________________________________________________

PyTorch

PyTorch is also an open-source Python library for Machine Learning based on Torch, which is implemented in C language and used for Machine learning. It has numerous tools and libraries supported on the computer version, Natural Language Processing (NLP) and many other Machine Learning programs. This library also allows users to perform computational tasks on Tensor with GPU acceleration.
Example:

import torch as tch
d_type = tch.float
device_1 = tch.device("cpu")
# Use device = tch.device("cuda:0") for GPU
 
# Here, N_1 is batch size; D_in_1 is input dimension;
# H_1 is hidden dimension; D_out_1 is output dimension.
N_1 = 62
D_in_1 = 1000
H_1 = 110
D_out_1 = 11
 
# Now, we will create random input and output data
K = tch.randn(N_1, D_in_1, device = device_1, dtype = d_type)
R = tch.randn(N_1, D_out_1, device = device_1, dtype = d_type)
 
# Then, we will Randomly initialize weights
K_1 = tch.randn(D_in_1, H_1, device = device_1, dtype = d_type)
K_2 = tch.randn(H_1, D_out_1, device = device_1, dtype = d_type)
 
learning_rate_1 = 1e-6
for Q in range(500):
    # Now, we will put Forward pass: compute predicted y
    h_1 = K.mm(K_1)
    h_relu_1 = h_1.clamp(min = 0)
    y_pred_1 = h_relu_1.mm(K_2)
 
    # Compute and print loss
    loss = (y_pred_1 - R).pow(2).sum().item()
    print (Q, loss)
 
    # Then we will Backprop to compute gradients of w1 and w2 with respect to loss
    grad_y_pred = 2.0 * (y_pred_1 - R)
    grad_K_2 = h_relu_1.t().mm(grad_y_pred)
    grad_h_relu = grad_y_pred.mm(K_2.t())
    grad_h = grad_h_relu.clone()
    grad_h[h_1 < 0] = 0
    grad_K_1 = K.t().mm(grad_h)
 
    # Then we will Update the weights by using gradient descent
    K_1 -= learning_rate_1 * grad_K_1
    K_2 -= learning_rate_1 * grad_K_2

Output:
0 35089116.0
1 33087792.0
2 42227192.0
3 56113208.0
4 61125684.0
5 45541204.0
6 21011108.0
7 6972017.0
8 2523046.5
9 1342124.5
10 950067.5625
11 753290.25
12 620475.875
13 519006.71875
14 437975.9375
15 372063.125
16 317840.8125
17 272874.46875
18 235348.421875
.
.
.
497 7.426088268402964e-05
498 7.348413055296987e-05
499 7.258950790856034e-05

Pandas

Pandas is a Python library that is mainly used for data analysis. The users have to prepare the dataset before using it for training the machine learning. Pandas make it easy for the developers as it is developed specifically for data extraction. It has a wide variety of tools for analysing data in detail, providing high-level data structures.
Example:

import pandas as pad
 
data_1 = {"Countries": ["Bhutan", "Cape Verde", "Chad", "Estonia", "Guinea", "Kenya", "Libya", "Mexico"],
       "capital": ["Thimphu", "Praia", "N'Djamena", "Tallinn", "Conakry", "Nairobi", "Tripoli", "Mexico City"],
       "Currency": ["Ngultrum", "Cape Verdean escudo", "CFA Franc", "Estonia Kroon; Euro", "Guinean franc", "Kenya shilling", "Libyan dinar", "Mexican peso"],
       "population": [20.4, 143.5, 12.52, 135.7, 52.98, 76.21, 34.28, 54.32] }
 
data_1_table = pad.DataFrame(data_1)
print(data_1_table)

Output:
    Countries      capital             Currency  population
0      Bhutan      Thimphu             Ngultrum       20.40
1  Cape Verde        Praia  Cape Verdean escudo      143.50
2        Chad    N'Djamena            CFA Franc       12.52
3     Estonia      Tallinn  Estonia Kroon; Euro      135.70
4      Guinea      Conakry        Guinean franc       52.98
5       Kenya      Nairobi       Kenya shilling       76.21
6       Libya      Tripoli         Libyan dinar       34.28
7      Mexico  Mexico City         Mexican peso       54.32

Matplotlib

Matplotlib is a Python library that is used for data visualization. It is used by developers when they want to visualize the data and its patterns. It is a 2-D plotting library that is used to create 2-D graphs and plots.
It has a module pyplot which is used for plotting graphs, and it provides different features for control line styles, font properties, formatting axes and many more. Matplotlib provides different types of graphs and plots such as histograms, error charts, bar charts and many more.
Example 1:

import matplotlib.pyplot as plot
import numpy as nup
 
# Prepare the data
K = nup.linspace(2, 4, 8)
R = nup.linspace(5, 7, 9)
Q = nup.linspace(0, 1, 3)
 
# Plot the data
plot.plot(K, K, label = 'K')
plot.plot(R, R, label = 'R')
plot.plot(Q, Q, label = 'Q')
 
# Add a legend
plot.legend()
 
# Show the plot
plot.show()

Output:

Example 2:

import matplotlib.pyplot as plot
  
# Creating dataset-1
K_1 = [8, 4, 6, 3, 5, 10, 
      13, 16, 12, 21]
  
R_1 = [11, 6, 13, 15, 17, 5, 
      3, 2, 8, 19]
  
# Creating dataset2
K_2 = [6, 9, 18, 14, 16, 15,
      11, 16, 12, 20]
  
R_2 = [16, 4, 10, 13, 18, 
      20, 6, 2, 17, 15]
  
plot.scatter(K_1, R_1, c = "Black", 
            linewidths = 2, 
            marker = "s", 
            edgecolor = "Brown", 
            s = 50)
  
plot.scatter(K_2, R_2, c = "Purple",
            linewidths = 2,
            marker = "^", 
            edgecolor = "Grey", 
            s = 200)
  
plt.xlabel ("X-axis")
plt.ylabel ("Y-axis")
print ("Scatter Plot")
plt.show()

Output:

Conclusion
In this tutorial, we have discussed about different libraries of Python which are used for performing Machine learning tasks. We have also shown different examples of each library.


Next TopicPython Program to Display Calendar of Given Year




← prev
next →




